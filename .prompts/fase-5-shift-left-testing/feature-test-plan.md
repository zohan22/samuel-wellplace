Act√∫a como QA Lead experto en Shift-Left Testing, Test Strategy y Quality Analysis.

**‚ö†Ô∏è WORKFLOW:** Este prompt sigue el principio **JIRA-FIRST ‚Üí LOCAL MIRROR**

---

## üì• Input Requerido

### 1. Epic Path Local (OBLIGATORIO)

**Formato:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/`
**Ejemplo:** `.context/PBI/epics/EPIC-UPEX-13-user-authentication/`

**Importante:** {ISSUE_NUM} es asignado secuencialmente por Jira (1, 2, 13, 45...) sin ceros a la izquierda

**‚ö†Ô∏è IMPORTANTE - Diferencia entre Nomenclaturas:**

- **Path Local (carpeta):** `EPIC-UPEX-13-user-authentication` ‚Üê Nomenclatura de carpetas
- **Jira Key (real):** `UPEX-13` ‚Üê Key real del issue en Jira

**Nota:** Los n√∫meros de issue son id√©nticos en ambos formatos (ej: 13). La diferencia est√° solo en el prefijo:

- Carpeta local: `EPIC-` + Jira Key
- Jira: Solo el Key (sin prefijo EPIC-)

**Proceso:**

1. **Usuario proporciona:** Path de la carpeta epic local
2. **Prompt lee:** Archivo `epic.md` de esa carpeta
3. **Prompt extrae:** Campo `**Jira Key:**` del epic.md (formato real: UPEX-123)
4. **Prompt usa:** Ese Jira Key real para operaciones MCP de Atlassian

**Uso del path:**

- Leer epic.md local para obtener Jira Key real
- Leer el epic actual de Jira con MCP (Paso 5)
- Actualizar el epic en Jira con findings (Paso 5)
- Agregar comentario con test plan completo (Paso 6)
- Generar archivo feature-test-plan.md en esa carpeta (Paso 7)

---

### 2. Contexto de Negocio (OBLIGATORIO)

- Business Model: [leer .context/idea/business-model.md]
- Executive Summary: [leer .context/PRD/executive-summary.md]
- User Personas: [leer .context/PRD/user-personas.md]
- User Journeys: [leer .context/PRD/user-journeys.md]

---

### 3. Contexto T√©cnico (OBLIGATORIO)

- Functional Specs: [leer .context/SRS/functional-specs.md - COMPLETO]
- Non-Functional Specs: [leer .context/SRS/non-functional-specs.md]
- Architecture Specs: [leer .context/SRS/architecture-specs.md]
- API Contracts: [leer .context/SRS/api-contracts.yaml]

---

### 4. Contexto de la Feature (OBLIGATORIO)

**Paso 1: Leer Epic Local y Extraer Jira Key**

- Epic (local): [leer {EPIC_PATH}/epic.md proporcionado por el usuario]
- **Extraer del epic.md:** Campo `**Jira Key:**` (ej: UPEX-123)
- **Guardar:** Jira Key real para usar en operaciones MCP

**Paso 2: Obtener Epic de Jira**

- Epic (Jira): [usar MCP de Atlassian con el Jira Key real extra√≠do del paso 1]

**Paso 3: Leer Stories**

- Todas las stories de la √©pica: [leer todos los story.md en {EPIC_PATH}/stories/]

---

## üì§ Output Generado

### En Jira (v√≠a MCP de Atlassian):

1. **Epic actualizado** con test strategy summary y label `test-plan-ready`
2. **Comentario agregado** con test plan completo y tags al equipo

### En Local:

1. **Archivo:** `.context/PBI/epics/EPIC-{...}/feature-test-plan.md`
2. **Contenido:** Mirror exacto del comentario en Jira

### Para Usuario:

1. **Reporte:** Resumen ejecutivo con critical questions y next steps (Paso 8)

---

## üéØ FLUJO DE TRABAJO

Este prompt trabaja en **8 pasos** organizados en 2 partes, siguiendo **JIRA-FIRST ‚Üí LOCAL MIRROR**:

---

### üìä PARTE 1: AN√ÅLISIS Y DISE√ëO

#### Paso 1: An√°lisis de Contexto

- Entender el valor de negocio de la √©pica
- Identificar usuarios afectados
- Analizar arquitectura involucrada

#### Paso 2: An√°lisis de Riesgos

- Identificar riesgos t√©cnicos
- Identificar riesgos de negocio
- Identificar puntos de integraci√≥n cr√≠ticos

#### Paso 3: Estrategia de Testing

- Definir niveles de testing requeridos
- Definir tipos de testing por story
- Definir scope de testing

#### Paso 4: An√°lisis Cr√≠tico & Plan de Testing

- Identificar ambig√ºedades en √©pica/stories
- Generar preguntas para PO/Dev
- Sugerir mejoras antes de implementaci√≥n
- Entry/Exit criteria
- Test data requirements
- Estimaci√≥n de test cases por story

---

### üîÑ PARTE 2: INTEGRACI√ìN Y OUTPUT

#### Paso 5: Update Epic in Jira

- Agregar test strategy summary y label `test-plan-ready`

#### Paso 6: Add Test Plan as Comment in Jira Epic

- Agregar test plan completo como comentario con tags al equipo

#### Paso 7: Generate Local feature-test-plan.md

- Crear mirror local del comentario de Jira

#### Paso 8: Final QA Feedback Report

- Generar resumen ejecutivo para el usuario

---

# Feature Test Plan: EPIC-{PROJECT_KEY}-{ISSUE_NUM} - [Epic Title]

**Fecha:** [YYYY-MM-DD]
**QA Lead:** [Nombre o "TBD"]
**Epic Jira Key:** [{PROJECT_KEY}-{ISSUE_NUM}]
**Status:** Draft | In Review | Approved

---

## üìã Business Context Analysis

### Business Value

[Explicar el valor de negocio de esta √©pica seg√∫n Business Model Canvas y Executive Summary]

**Key Value Proposition:**

- [Valor 1 que aporta al usuario]
- [Valor 2 que aporta al negocio]

**Success Metrics (KPIs):**

- [KPI 1 del Executive Summary que esta √©pica impacta]
- [KPI 2 del Executive Summary que esta √©pica impacta]

**User Impact:**
(Analizar .context/PRD/user-personas.md para identificar qu√© personas son afectadas por esta √©pica)

- [User Persona identificada del PRD]: [C√≥mo le afecta espec√≠ficamente seg√∫n el epic.md]
- [Otra User Persona si aplica]: [C√≥mo le afecta]

**Critical User Journeys:**
(Analizar .context/PRD/user-journeys.md para identificar qu√© journeys habilita o modifica esta √©pica)

- [Journey identificado del PRD]
- [Otro Journey si aplica]

(Donde las personas y journeys se determinan analizando el PRD del proyecto actual y relacion√°ndolos con el scope del epic)

---

## üèóÔ∏è Technical Architecture Analysis

### Architecture Components Involved

**Frontend:**
(Analizar .context/SRS/architecture-specs.md y el epic.md para identificar)

- Componentes a crear/modificar: [listar seg√∫n an√°lisis del SRS]
- P√°ginas/rutas afectadas: [listar seg√∫n an√°lisis del SRS]

**Backend:**
(Analizar .context/SRS/api-contracts.yaml y architecture-specs.md)

- APIs a crear/modificar: [referenciar endpoints espec√≠ficos de api-contracts.yaml]
- Servicios de negocio afectados: [listar seg√∫n an√°lisis del SRS]

**Database:**
(Analizar .context/SRS/architecture-specs.md)

- Tablas involucradas: [listar tablas espec√≠ficas del schema seg√∫n SRS]
- Queries cr√≠ticos: [identificar queries complejos o de alto impacto]

**External Services:**
(Analizar .context/SRS/architecture-specs.md y epic.md)

- APIs externas: [listar servicios externos espec√≠ficos seg√∫n SRS]
- Third-party services: [ej: procesador de pagos, servicio de email, etc.]

(Donde todos los componentes, APIs, tablas y servicios se determinan analizando el SRS/PRD/epic del proyecto actual)

### Integration Points (Critical for Testing)

[Basado en architecture-specs.md, identificar puntos de integraci√≥n]

**Internal Integration Points:**

- Frontend ‚Üî Backend API
- Backend ‚Üî Database
- Backend ‚Üî Auth Service
- [Otros m√≥dulos internos]

**External Integration Points:**

- [Sistema] ‚Üî [Servicio externo 1]
- [Sistema] ‚Üî [Servicio externo 2]

**Data Flow:**

```
[Describir flujo de datos cr√≠tico]
User ‚Üí Frontend ‚Üí API Gateway ‚Üí Service X ‚Üí Database
                              ‚Üì
                         External Service
```

---

## üö® Risk Analysis

### Technical Risks

#### Risk 1: [Descripci√≥n del riesgo t√©cnico]

- **Impact:** High | Medium | Low
- **Likelihood:** High | Medium | Low
- **Area Affected:** [Frontend | Backend | Database | Integration]
- **Mitigation Strategy:**
  - [Estrategia 1]
  - [Testing approach espec√≠fico]
- **Test Coverage Required:** [Qu√© test cases necesitamos para mitigar]

#### Risk 2: [Descripci√≥n del riesgo t√©cnico]

- **Impact:** ...
- **Likelihood:** ...
- **Area Affected:** ...
- **Mitigation Strategy:** ...
- **Test Coverage Required:** ...

---

### Business Risks

#### Risk 1: [Descripci√≥n del riesgo de negocio]

- **Impact on Business:** [C√≥mo afecta KPIs o user experience]
- **Impact on Users:** [Qu√© user personas se ven afectadas]
- **Likelihood:** High | Medium | Low
- **Mitigation Strategy:**
  - [Qu√© testing hacemos para prevenir]
  - [Qu√© validaciones de negocio agregamos]
- **Acceptance Criteria Validation:** [Validar que acceptance criteria cubran este riesgo]

#### Risk 2: [Descripci√≥n del riesgo de negocio]

- **Impact on Business:** ...
- **Impact on Users:** ...
- **Likelihood:** ...
- **Mitigation Strategy:** ...

---

### Integration Risks

[Identificar riesgos en puntos de integraci√≥n identificados anteriormente]

#### Integration Risk 1: [Descripci√≥n]

- **Integration Point:** [Frontend ‚Üî API | API ‚Üî Database | etc.]
- **What Could Go Wrong:** [Escenarios de falla]
- **Impact:** High | Medium | Low
- **Mitigation:**
  - Integration tests espec√≠ficos
  - Contract testing (si aplica)
  - Mocking strategy para testing aislado

---

## ‚ö†Ô∏è Critical Analysis & Questions for PO/Dev

### Ambiguities Identified

[Analizar epic.md y todos los story.md de la √©pica para identificar ambig√ºedades]

**Ambiguity 1:** [Descripci√≥n de la ambig√ºedad]

- **Found in:** STORY-{PROJECT_KEY}-{ISSUE_NUM}
- **Question for PO:** [Pregunta espec√≠fica]
- **Impact if not clarified:** [Qu√© problemas puede causar]

**Ambiguity 2:** [Descripci√≥n]

- **Found in:** EPIC-{PROJECT_KEY}-{ISSUE_NUM} scope
- **Question for Dev:** [Pregunta t√©cnica]
- **Impact if not clarified:** ...

---

### Missing Information

[Identificar qu√© informaci√≥n falta en epic.md o stories para poder testear correctamente]

**Missing 1:** [Qu√© falta]

- **Needed for:** [Por qu√© es cr√≠tico para testing]
- **Suggestion:** [Qu√© agregar a la story/epic]

**Missing 2:** [Qu√© falta]

- **Needed for:** ...
- **Suggestion:** ...

---

### Suggested Improvements (Before Implementation)

[Sugerencias para mejorar stories ANTES de que Dev empiece a implementar]

**Improvement 1:** [Sugerencia]

- **Story Affected:** STORY-{PROJECT_KEY}-{ISSUE_NUM}
- **Current State:** [C√≥mo est√° ahora]
- **Suggested Change:** [C√≥mo deber√≠a estar]
- **Benefit:** [Por qu√© mejora la quality]

**Improvement 2:** [Sugerencia]

- **Story Affected:** ...
- **Current State:** ...
- **Suggested Change:** ...
- **Benefit:** ...

---

## üéØ Test Strategy

### Test Scope

**In Scope:**

- Functional testing (UI, API, Database)
- Integration testing (internal + external services)
- Non-functional testing (Performance, Security seg√∫n NFRs)
- Cross-browser testing (Chrome, Firefox, Safari)
- Mobile responsiveness (iOS Safari, Android Chrome)
- API contract validation (seg√∫n api-contracts.yaml)
- Data validation (input/output seg√∫n SRS)

**Out of Scope (For This Epic):**

- [Features que NO se testean en esta √©pica]
- [Testing que se deja para otras √©picas]
- [Testing que se contrata externo: penetration testing, load testing extremo, etc.]

---

### Test Levels

#### Unit Testing

- **Coverage Goal:** > 80% code coverage
- **Focus Areas:**
  - Business logic functions/methods
  - Data validation functions
  - Utility functions
- **Responsibility:** Dev team (pero QA valida que existan)

#### Integration Testing

- **Coverage Goal:** All integration points identified above
- **Focus Areas:**
  - Frontend ‚Üî Backend API (seg√∫n api-contracts.yaml)
  - Backend ‚Üî Database
  - Backend ‚Üî External Services (mocked)
- **Responsibility:** QA + Dev (pair programming)

#### End-to-End (E2E) Testing

- **Coverage Goal:** Critical user journeys completos
- **Tool:** Playwright
- **Focus Areas:**
  - [User Journey 1 identificado arriba]
  - [User Journey 2 identificado arriba]
  - Happy paths completos
  - Error scenarios cr√≠ticos
- **Responsibility:** QA team

#### API Testing

- **Coverage Goal:** 100% de endpoints de esta √©pica (seg√∫n api-contracts.yaml)
- **Tool:** Postman/Newman o Playwright API
- **Focus Areas:**
  - Contract validation (request/response seg√∫n OpenAPI spec)
  - Status codes correctos
  - Error handling
  - Authentication/Authorization
- **Responsibility:** QA team

---

### Test Types per Story

Por cada story de esta √©pica, se deben cubrir:

**Positive Test Cases:**

- Happy path (flujo exitoso)
- Valid data variations (diferentes datos v√°lidos)

**Negative Test Cases:**

- Invalid input data
- Missing required fields
- Unauthorized access attempts
- Boundary violations

**Boundary Test Cases:**

- Min/max values
- Empty/null values
- Edge cases espec√≠ficos del dominio

**Exploratory Testing:**

- [√Åreas que requieren exploratory testing - explicar por qu√©]
- Sugerencia: Hacer exploratory testing ANTES de implementaci√≥n (usando mockups/prototypes)

---

## üìä Test Cases Summary by Story

[Por cada story de la √©pica, estimar cu√°ntos test cases se necesitan - SIN forzar n√∫mero m√≠nimo]

### STORY-{PROJECT_KEY}-{ISSUE_NUM}: [Story Title]

**Complexity:** Low | Medium | High
**Estimated Test Cases:** [N√∫mero realista - puede ser 1, puede ser 20]

- Positive: [X] test cases
- Negative: [Y] test cases
- Boundary: [Z] test cases
- Integration: [W] test cases (si aplica)
- API: [V] test cases (si aplica)

**Rationale for estimate:**
[Explicar por qu√© ese n√∫mero - complejidad, integration points, edge cases identificados]

**Parametrized Tests Recommended:** Yes | No
[Si Yes, explicar qu√© tests se benefician de parametrizaci√≥n]

---

### STORY-{PROJECT_KEY}-{ISSUE_NUM}: [Story Title]

**Complexity:** ...
**Estimated Test Cases:** ...

- ...

**Rationale for estimate:** ...
**Parametrized Tests Recommended:** ...

---

[Repetir para todas las stories de la √©pica]

---

### Total Estimated Test Cases for Epic

**Total:** [Suma de todos los test cases estimados]
**Breakdown:**

- Positive: [X]
- Negative: [Y]
- Boundary: [Z]
- Integration: [W]
- API: [V]

---

## üóÇÔ∏è Test Data Requirements

### Test Data Strategy

**Valid Data Sets:**
[Basado en user personas y SRS, definir datos v√°lidos realistas]

- User data: [Ejemplos de usuarios v√°lidos seg√∫n personas]
- Transaction data: [Ejemplos de transacciones/operaciones v√°lidas]
- [Otros datos seg√∫n el dominio]

**Invalid Data Sets:**

- [Ejemplos de datos inv√°lidos que debemos probar]
- [Casos de input malicioso - SQL injection, XSS, etc.]

**Boundary Data Sets:**

- Min/Max values: [Seg√∫n validaciones del SRS]
- Empty/null values
- Special characters
- Unicode characters (si aplica internacionalizaci√≥n)

**Test Data Management:**

- ‚úÖ Use Faker.js for generating realistic test data
- ‚úÖ Create data factories for common entities
- ‚ùå NO hardcodear datos est√°ticos en tests
- ‚úÖ Clean up test data after test execution

---

### Test Environments

**Staging Environment:**

- URL: [Staging URL]
- Database: [Staging DB]
- External Services: [Mocked | Real staging versions]
- **Purpose:** Primary testing environment

**Production Environment:**

- URL: [Production URL]
- **Purpose:** ONLY smoke tests post-deployment
- **Restrictions:** NO destructive tests, NO test data creation

---

## ‚úÖ Entry/Exit Criteria

### Entry Criteria (Per Story)

Testing can start when:

- [ ] Story is fully implemented and deployed to staging
- [ ] Code review is approved by 2+ reviewers
- [ ] Unit tests exist and are passing (>80% coverage)
- [ ] Dev has done smoke testing and confirms basic functionality works
- [ ] No blocker bugs exist in dependent stories
- [ ] Test data is prepared and available in staging
- [ ] API documentation is updated (if API changes)

### Exit Criteria (Per Story)

Story is considered "Done" from QA perspective when:

- [ ] All test cases are executed
- [ ] Critical/High priority test cases: 100% passing
- [ ] Medium/Low priority test cases: ‚â•95% passing
- [ ] All critical and high bugs are resolved and verified
- [ ] Medium bugs have mitigation plan or are scheduled
- [ ] Regression testing passed (if changes affect other features)
- [ ] Non-functional requirements validated (performance, security)
- [ ] Test execution report is generated and shared
- [ ] Known issues are documented in release notes

### Epic Exit Criteria

Epic is considered "Done" from QA perspective when:

- [ ] ALL stories meet individual exit criteria
- [ ] Integration testing across all stories is complete
- [ ] E2E testing of critical user journeys is complete and passing
- [ ] API contract testing is complete (all endpoints validated)
- [ ] Non-functional testing is complete (NFRs from SRS validated)
- [ ] Exploratory testing session completed (findings documented)
- [ ] No critical or high bugs open
- [ ] QA sign-off document is created and approved

---

## üìù Non-Functional Requirements Validation

[Basado en .context/SRS/non-functional-specs.md, identificar NFRs que aplican a esta √©pica]

### Performance Requirements

**NFR-P-XXX:** [Descripci√≥n del NFR de performance]

- **Target:** [M√©trica espec√≠fica - ej: "Page load < 2s"]
- **Test Approach:** [C√≥mo lo vamos a validar]
- **Tools:** [Lighthouse, WebPageTest, etc.]

### Security Requirements

**NFR-S-XXX:** [Descripci√≥n del NFR de seguridad]

- **Requirement:** [Requerimiento espec√≠fico - ej: "All passwords hashed with bcrypt"]
- **Test Approach:** [C√≥mo lo vamos a validar]
- **Tools:** [OWASP ZAP, manual testing, etc.]

### Usability Requirements

**NFR-U-XXX:** [Descripci√≥n del NFR de usabilidad]

- **Requirement:** [Requerimiento espec√≠fico]
- **Test Approach:** [C√≥mo lo vamos a validar]

---

## üîÑ Regression Testing Strategy

**Regression Scope:**
[Identificar qu√© √°reas del sistema existente pueden verse afectadas por esta √©pica]

- [ ] Feature A: [C√≥mo puede afectarse]
- [ ] Feature B: [C√≥mo puede afectarse]

**Regression Test Execution:**

- Run automated regression suite before starting epic testing
- Re-run after all stories are complete
- Focus on integration points identified in architecture analysis

---

## üìÖ Testing Timeline Estimate

**Estimated Duration:** [X sprints | Y weeks]

**Breakdown:**

- Test case design: [X days]
- Test data preparation: [Y days]
- Test execution (per story): [Z days per story]
- Regression testing: [W days]
- Bug fixing cycles: [V days - buffer]
- Exploratory testing: [U days]

**Dependencies:**

- Depends on: [√âpicas que deben completarse primero]
- Blocks: [√âpicas que dependen de esta]

---

## üõ†Ô∏è Tools & Infrastructure

**Testing Tools:**

- E2E Testing: Playwright
- API Testing: Postman/Newman or Playwright API
- Unit Testing: Vitest (frontend), Jest (backend)
- Performance Testing: Lighthouse, WebPageTest
- Security Testing: OWASP ZAP (if applicable)
- Test Data: Faker.js

**CI/CD Integration:**

- [ ] Tests run automatically on PR creation
- [ ] Tests run on merge to main branch
- [ ] Tests run on deployment to staging
- [ ] Smoke tests run on deployment to production

**Test Management:**

- Jira Xray (test cases linked to stories)
- Test execution reports in Xray
- Bug tracking in Jira

---

## üìä Metrics & Reporting

**Test Metrics to Track:**

- Test cases executed vs. total
- Test pass rate
- Bug detection rate
- Bug fix rate
- Test coverage (code coverage from unit tests)
- Time to test (per story)

**Reporting Cadence:**

- Daily: Test execution status
- Per Story: Test completion report
- Per Epic: Comprehensive QA sign-off report

---

## üìù PARTE 2: Integraci√≥n y Output

**‚ö†Ô∏è IMPORTANTE:** Esta parte implementa el flujo **JIRA-FIRST ‚Üí LOCAL MIRROR** para mantener consistencia con el proceso de gesti√≥n de epics.

---

### Paso 5: Update Epic in Jira

**Objetivo:** Actualizar el epic en Jira CON los findings cr√≠ticos del an√°lisis de testing, ANTES de generar archivo local.

**Herramienta:** MCP de Atlassian

**Pasos a ejecutar:**

1. **Leer epic actual de Jira:**
   - Usar MCP de Atlassian para obtener el epic
   - Input: Jira Key real extra√≠do de epic.md (ej: UPEX-123)
   - ‚ö†Ô∏è **NO usar** nomenclatura de carpeta (EPIC-UPEX-001)
   - Obtener: description actual

2. **Preparar contenido del summary:**

   Basado en an√°lisis de Pasos 1-4, preparar:
   - **Top Critical Risks** (de Paso 2)
   - **Test Coverage Summary** (de Paso 4)
   - **Critical Questions** (de Paso 4)

3. **Actualizar epic en Jira:**
   - Usar MCP de Atlassian para editar el epic
   - Agregar nueva secci√≥n al description con el siguiente contenido:

   ***

   ## üß™ QA Test Strategy - Shift-Left Analysis

   **Analysis Date:** [YYYY-MM-DD]
   **Status:** Test Plan Ready

   ### Critical Risks Identified

   [Resumen de top 3 riesgos t√©cnicos/negocio con mayor impacto]

   ### Test Coverage Summary
   - **Total Estimated Test Cases:** [X]
   - **Integration Points:** [Y]
   - **Critical User Journeys:** [Z]
   - **Test Complexity:** Low | Medium | High

   ### Critical Questions for Team

   [Indicar que hay preguntas cr√≠ticas en comentario - ver detalles abajo]

   ### Test Strategy
   - Levels: Unit, Integration, E2E, API
   - Tools: Playwright, Vitest, Postman
   - Timeline: [X sprints/weeks estimated]

   ***
   - Agregar label: `test-plan-ready`

**Output esperado:**

- ‚úÖ Epic actualizado en Jira con test strategy summary
- ‚úÖ Label `test-plan-ready` agregado
- ‚úÖ Description enriquecido con an√°lisis de QA

---

### Paso 6: Add Feature Test Plan as Comment in Jira

**Objetivo:** Agregar TODO el feature test plan como comentario en el epic de Jira para m√°xima visibilidad del equipo.

**Herramienta:** MCP de Atlassian

**Estructura del comentario:**

```
## üìã Feature Test Plan - Generated [Date]

**QA Lead:** [Nombre o "AI-Generated"]
**Status:** Draft - Pending Team Review

---

[PEGAR AQU√ç TODO EL CONTENIDO GENERADO DESDE "Feature Test Plan: EPIC-..." HASTA "Metrics & Reporting"]

---

## üì¢ Action Required

**@[Product Owner]:**

- [ ] Review ambiguities and missing information (see Critical Analysis section)
- [ ] Answer critical questions for PO
- [ ] Validate risk analysis and business impact
- [ ] Confirm test scope is complete and correct

**@[Dev Lead]:**

- [ ] Review technical risks and mitigation strategies
- [ ] Validate integration points identified
- [ ] Confirm architecture analysis is accurate
- [ ] Answer technical questions

**@[QA Team]:**

- [ ] Review test strategy and estimates
- [ ] Validate test levels and types per story
- [ ] Confirm test data requirements
- [ ] Prepare test environments and tools

---

**Next Steps:**

1. Team discusses critical questions and ambiguities in refinement
2. PO/Dev provide answers and clarifications
3. QA begins test case design per story (use story-test-cases.md prompt)
4. Team validates entry/exit criteria before sprint starts
5. Dev starts implementation ONLY after critical questions resolved

---

**Documentation:** Full test plan also available at:
`.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/feature-test-plan.md`
```

**Pasos a ejecutar:**

1. Usar MCP de Atlassian para agregar comentario al epic
2. Input: Epic Jira Key + contenido completo del comentario
3. Mencionar en el comentario a los miembros del equipo (@PO, @Dev, @QA) seg√∫n configuraci√≥n del proyecto

**Output esperado:**

- ‚úÖ Comentario creado en Jira con test plan completo
- ‚úÖ Equipo notificado v√≠a mentions
- ‚úÖ Checklist de acciones agregado para follow-up

---

### Paso 7: Generate Local feature-test-plan.md (Mirroring)

**Objetivo:** Crear archivo local `.md` como MIRROR del comentario en Jira para version control y documentaci√≥n offline.

**Path:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/feature-test-plan.md`

**Contenido:** ID√âNTICO al contenido generado en Paso 6 (todo el test plan)

**Output esperado:**

- ‚úÖ Archivo `feature-test-plan.md` creado localmente
- ‚úÖ Contenido es MIRROR exacto del comentario en Jira
- ‚úÖ Disponible para git versioning

---

### Paso 8: Final QA Feedback Report

**Objetivo:** Reportar al USUARIO el resumen ejecutivo y acciones pendientes.

**Formato del reporte:**

---

## ‚úÖ Feature Test Plan - Execution Summary

**Epic:** [EPIC-KEY] - [Title]
**Analysis Date:** [YYYY-MM-DD]

---

### üìä Summary

**Epic Complexity:** Low | Medium | High
**Total Estimated Test Cases:** [X]
**Critical Risks Identified:** [Y]
**Integration Points:** [Z]
**Estimated Testing Duration:** [X sprints/weeks]

---

### üö® Top 3 Critical Risks

**Risk 1:** [Descripci√≥n]

- **Impact:** High
- **Area:** [Technical | Business | Integration]
- **Mitigation:** [Estrategia]

**Risk 2:** [Descripci√≥n]

- **Impact:** High/Medium
- **Area:** [Technical | Business | Integration]
- **Mitigation:** [Estrategia]

**Risk 3:** [Descripci√≥n]

- **Impact:** Medium
- **Area:** [Technical | Business | Integration]
- **Mitigation:** [Estrategia]

---

### ‚ùì Critical Questions Requiring PO/Dev Input

**Question 1 (For PO):** [Pregunta sobre negocio]

- **Context:** [Por qu√© es importante]
- **Impact if not answered:** [Qu√© riesgo representa]

**Question 2 (For Dev):** [Pregunta t√©cnica]

- **Context:** [Por qu√© es importante]
- **Impact if not answered:** [Qu√© riesgo representa]

**Question 3 (For PO/Dev):** [Pregunta adicional si aplica]

- **Context:** ...
- **Impact if not answered:** ...

---

### üí° Suggested Epic/Story Improvements

**Improvement 1:** [Sugerencia]

- **Story/Epic Affected:** [KEY]
- **Current State:** [Problema identificado]
- **Suggested Change:** [C√≥mo mejorarlo]
- **Benefit:** [Por qu√© es importante]

**Improvement 2:** [Si aplica]

- **Story/Epic Affected:** ...
- **Current State:** ...
- **Suggested Change:** ...
- **Benefit:** ...

---

### üéØ Test Strategy Highlights

**Test Levels:**

- Unit Testing: Dev responsibility (>80% coverage goal)
- Integration Testing: QA + Dev collaboration
- E2E Testing: [X] critical user journeys
- API Testing: [Y] endpoints to validate

**Test Types per Story:**

- Positive: [X] test cases
- Negative: [Y] test cases
- Boundary: [Z] test cases
- Integration: [W] test cases

**Key Integration Points:**

- [Integration Point 1]
- [Integration Point 2]
- [Integration Point 3]

---

### ‚úÖ What Was Done

**Jira Updates:**

- ‚úÖ Epic updated with test strategy summary
- ‚úÖ Label `test-plan-ready` added
- ‚úÖ Test plan added as comment in Jira epic
- ‚úÖ Team members tagged for review (@PO, @Dev, @QA)

**Local Files:**

- ‚úÖ `feature-test-plan.md` created at: `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/`

**Analysis Completed:**

- ‚úÖ Business context analyzed (value, users, journeys)
- ‚úÖ Technical architecture analyzed (components, integration points)
- ‚úÖ Risk analysis completed (technical, business, integration)
- ‚úÖ Test strategy defined (levels, types, scope)
- ‚úÖ Test estimates per story calculated
- ‚úÖ Entry/Exit criteria defined

---

### üéØ Next Steps (Team Action Required)

**Immediate Actions:**

1. **PO:** Review critical questions in Jira comment and provide answers
2. **Dev Lead:** Review technical risks and validate integration points
3. **Team:** Schedule refinement session to discuss ambiguities and improvements
4. **QA:** Wait for clarifications before starting test case design per story

**Before Sprint Starts:**

5. **All:** Ensure all critical questions are answered
6. **PO:** Approve or provide feedback on suggested improvements
7. **QA:** Begin test case design for each story using `story-test-cases.md` prompt
8. **Team:** Validate entry criteria can be met for each story

**During Epic Implementation:**

9. **QA:** Execute test cases as stories are completed
10. **Team:** Address bugs and issues as they arise
11. **QA:** Track metrics and report progress daily

---

**‚ö†Ô∏è BLOCKER:** Epic should NOT start implementation until critical questions are resolved by PO/Dev.

**Jira Link:** [Link to epic in Jira]
**Local Test Plan:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/feature-test-plan.md`

---

---

## üéì Notes & Assumptions

**Assumptions:**

- [Listar assumptions que se est√°n haciendo para este plan]

**Constraints:**

- [Listar constraints - tiempo, recursos, herramientas, etc.]

**Known Limitations:**

- [Qu√© NO se puede testear o validar completamente]

**Exploratory Testing Sessions:**

- Recommended: [X] exploratory testing sessions BEFORE implementation
  - Session 1: [Objetivo - ej: Test with mockups/prototypes]
  - Session 2: [Objetivo - ej: Test edge cases not covered in stories]

---

## üìé Related Documentation

- **Epic:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/epic.md`
- **Stories:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-*/story.md`
- **Business Model:** `.context/idea/business-model.md`
- **PRD:** `.context/PRD/` (all files)
- **SRS:** `.context/SRS/` (all files)
- **Architecture:** `.context/SRS/architecture-specs.md`
- **API Contracts:** `.context/SRS/api-contracts.yaml`

---

**Formato:** Markdown estructurado siguiendo flujo **JIRA-FIRST ‚Üí LOCAL MIRROR**

---

## üîß Prerequisitos para Ejecutar Este Prompt

- ‚úÖ TODOS los archivos de contexto (idea, PRD, SRS) deben estar completos
- ‚úÖ Epic.md y todos los story.md de la √©pica deben existir
- ‚úÖ **Epic Path local disponible** (ej: `.context/PBI/epics/EPIC-UPEX-13-feature/`)
- ‚úÖ **Epic.md debe contener campo `Jira Key:`** con el key real (ej: UPEX-13)
- ‚úÖ **Acceso a MCP de Atlassian configurado y funcionando**
- ‚úÖ Tiempo para analizar cr√≠ticamente, no solo generar checklist

**‚ö†Ô∏è Validaci√≥n de epic.md:**

El archivo epic.md debe contener en su metadata:

```markdown
**Jira Key:** UPEX-13
```

Este es el Jira Key REAL del issue en Jira (NO la nomenclatura de carpeta).

**Nota:** El n√∫mero de issue (ej: 13) es el mismo en la nomenclatura de carpeta y en el Jira Key.

---

## üìã Flujo de Ejecuci√≥n (Para la IA)

### Input requerido del usuario:

```
Epic Path: .context/PBI/epics/EPIC-UPEX-13-nombre-feature/
```

**‚ö†Ô∏è Proceso Autom√°tico:**

1. Prompt lee: `.context/PBI/epics/EPIC-UPEX-13-nombre-feature/epic.md`
2. Prompt extrae: Campo `**Jira Key:**` (ej: UPEX-13)
3. Prompt usa: Jira Key real UPEX-13 para operaciones MCP

**Nota:** El n√∫mero de issue (13) es el mismo en la carpeta y en Jira. NO se usan formatos como 001 o XXX.

### Orden de ejecuci√≥n:

**Pre-requisito: Extraer Jira Key**

1. Leer `{EPIC_PATH}/epic.md` proporcionado por usuario
2. Extraer campo `**Jira Key:**` (ej: UPEX-13)
3. Guardar Jira Key real para usar en Pasos 5 y 6

**PARTE 1 - An√°lisis y Dise√±o:** 4. **Pasos 1-4:** Analizar contexto, riesgos, estrategia, test cases (contenido Markdown)

**PARTE 2 - Integraci√≥n y Output:** 5. **Paso 5:** Actualizar epic en Jira con test strategy summary (MCP Atlassian + Jira Key real) 6. **Paso 6:** Crear comentario en Jira con test plan completo (MCP Atlassian + Jira Key real) 7. **Paso 7:** Generar archivo local `feature-test-plan.md` en {EPIC_PATH}/ (Write tool) 8. **Paso 8:** Reportar resumen al usuario (Output)

### Herramientas a usar:

**MCP de Atlassian:**

- Para leer epic de Jira
- Para actualizar epic description y labels
- Para agregar comentario al epic

**File Operations:**

- Para crear archivo local feature-test-plan.md
- Para leer archivos de contexto (PRD, SRS, epic, stories)

---

## ‚ö†Ô∏è IMPORTANTE: Principios de Ejecuci√≥n

### Shift-Left Testing Philosophy:

- ‚úÖ **An√°lisis cr√≠tico primero, test planning despu√©s**
- ‚úÖ **Feedback temprano es M√ÅS valioso que test plan perfecto**
- ‚úÖ **Identificar riesgos ANTES de implementaci√≥n** (shift-left!)
- ‚úÖ **Test plan en comentarios** para visibilidad del equipo

### Test Planning Guidelines:

- ‚ùå **NO forzar n√∫mero m√≠nimo de test cases** - depende de complejidad de cada story
- ‚úÖ **Analizar riesgos exhaustivamente** - t√©cnicos, negocio, integraci√≥n
- ‚úÖ **Identificar ambig√ºedades** en epic y stories
- ‚úÖ **Hacer preguntas cr√≠ticas** - mejor clarificar que asumir

### Jira-First Workflow:

- ‚úÖ **SIEMPRE actualizar Jira primero, luego local** (consistencia)
- ‚úÖ **Test plan va en comentario** para m√°xima visibilidad
- ‚úÖ **Taggear al equipo** (@PO, @Dev, @QA)
- ‚úÖ **Agregar label `test-plan-ready`** para tracking

---

## üéØ Post-Generaci√≥n: Acciones del Equipo

### Inmediatamente despu√©s de ejecutar este prompt:

1. **PO debe:**
   - Revisar comentario en Jira con test plan
   - Responder "Critical Questions for PO"
   - Validar risk analysis y business impact
   - Confirmar test scope es completo y correcto

2. **Dev Lead debe:**
   - Revisar comentario en Jira con test plan
   - Responder "Technical Questions for Dev"
   - Validar integration points identificados
   - Confirmar architecture analysis es preciso
   - **NO empezar epic** hasta resolver preguntas cr√≠ticas

3. **QA debe:**
   - Revisar test strategy y estimates
   - Esperar respuestas de PO/Dev antes de empezar test case design
   - Preparar test environments y tools
   - Comenzar test case design por story usando `story-test-cases.md` prompt

4. **Usuario (quien ejecut√≥ el prompt) debe:**
   - Compartir link de Jira epic con equipo
   - Facilitar discusi√≥n de preguntas cr√≠ticas en refinement
   - Asegurar que preguntas sean respondidas antes de sprint

---

## üöÄ Workflow Completo: Epic ‚Üí Stories

### Orden recomendado:

1. ‚úÖ **Ejecutar `feature-test-plan.md` prompt** para el epic completo
2. ‚è∏Ô∏è **Esperar feedback** de PO/Dev sobre critical questions
3. ‚úÖ **Ejecutar `story-test-cases.md` prompt** para cada story individual
4. ‚è∏Ô∏è **Esperar feedback** de PO/Dev sobre cada story
5. ‚úÖ **Comenzar sprint** solo cuando todas las preguntas est√©n resueltas

**Beneficio de este workflow:**

- Test plan a nivel epic identifica riesgos globales
- Test cases a nivel story identifican gaps espec√≠ficos
- Ambos retroalimentan al PO/Dev ANTES de implementaci√≥n
- Reduce bugs, retrabajos y malentendidos

---

**Versi√≥n:** 3.0 - Jira-First + MCP Atlassian + Shift-Left Philosophy
**√öltima actualizaci√≥n:** 2025-01-05
**Cambios principales:**

- ‚úÖ Agregado flujo Jira-First (Pasos 5-8)
- ‚úÖ Integraci√≥n con MCP de Atlassian
- ‚úÖ Test plan en comentarios (no artefactos separados)
- ‚úÖ Refinamiento autom√°tico de epic en Jira
- ‚úÖ Consistencia con `story-test-cases.md` prompt
