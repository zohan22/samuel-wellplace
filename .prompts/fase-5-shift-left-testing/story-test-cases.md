Act√∫a como QA Engineer experto en Shift-Left Testing, Test Case Design y Critical Analysis.

**‚ö†Ô∏è WORKFLOW:** Este prompt sigue el principio **JIRA-FIRST ‚Üí LOCAL MIRROR**

---

## üì• Input Requerido

### 1. Story Path Local (OBLIGATORIO)

**Formato:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/`
**Ejemplo:** `.context/PBI/epics/EPIC-UPEX-13-auth/stories/STORY-UPEX-45-login/`

**‚ö†Ô∏è IMPORTANTE - Diferencia entre Nomenclaturas:**

- **Path Local (carpeta):** `STORY-UPEX-45-login` ‚Üê Nomenclatura de carpetas
- **Jira Key (real):** `UPEX-45` ‚Üê Key real del issue en Jira

**Nota:** Los n√∫meros de issue son id√©nticos en ambos formatos (ej: 45). La diferencia est√° solo en el prefijo STORY-

**Proceso:**

1. **Usuario proporciona:** Path de la carpeta story local
2. **Prompt lee:** Archivo `story.md` de esa carpeta
3. **Prompt extrae:** Campo `**Jira Key:**` del story.md (formato real: UPEX-456)
4. **Prompt usa:** Ese Jira Key real para operaciones MCP de Atlassian

**Uso del path:**

- Leer story.md local para obtener Jira Key real
- Leer la story actual de Jira con MCP (Paso 5)
- Actualizar la story en Jira con refinamientos (Paso 5)
- Agregar comentario con test cases (Paso 6)
- Generar archivo test-cases.md en esa carpeta (Paso 7)

---

### 2. Contexto de Negocio (OBLIGATORIO)

- Business Model: [leer .context/idea/business-model.md]
- Executive Summary: [leer .context/PRD/executive-summary.md]
- User Personas: [leer .context/PRD/user-personas.md]
- User Journeys: [leer .context/PRD/user-journeys.md]

---

### 3. Contexto T√©cnico (OBLIGATORIO)

- Functional Specs: [leer .context/SRS/functional-specs.md - COMPLETO]
- Non-Functional Specs: [leer .context/SRS/non-functional-specs.md]
- Architecture Specs: [leer .context/SRS/architecture-specs.md]
- API Contracts: [leer .context/SRS/api-contracts.yaml]

---

### 4. Contexto de la Story (OBLIGATORIO)

**Paso 1: Leer Story Local y Extraer Jira Keys**

- Story (local): [leer {STORY_PATH}/story.md proporcionado por el usuario]
- **Extraer del story.md:**
  - Campo `**Jira Key:**` de la story (ej: UPEX-456)
  - Campo `**Epic:**` para obtener el epic path local
- **Guardar:** Jira Keys reales para usar en operaciones MCP

**Paso 2: Leer Epic Local y Extraer Epic Jira Key**

- Epic (local): [leer epic.md del epic path encontrado en la story]
- **Extraer del epic.md:** Campo `**Jira Key:**` del epic (ej: UPEX-123)
- **Guardar:** Epic Jira Key real para leer comentarios

**Paso 3: Obtener Epic de Jira y Comentarios**

- Epic (Jira): [usar MCP de Atlassian con el Epic Jira Key real extra√≠do]
- **Epic Comments (Jira):** [usar MCP de Atlassian para leer comentarios del epic - buscar "Feature Test Plan"]
- Feature Test Plan (local): [leer feature-test-plan.md del epic path]

**Paso 4: Obtener Story de Jira**

- Story (Jira): [usar MCP de Atlassian con el Story Jira Key real extra√≠do del paso 1]

**‚ö†Ô∏è IMPORTANTE:** Leer los comentarios del epic en Jira proporciona contexto actualizado incluyendo:

- Respuestas de PO/Dev a preguntas cr√≠ticas
- Discusiones y clarificaciones adicionales
- Updates al test plan despu√©s de refinements

---

## üì§ Output Generado

### En Jira (v√≠a MCP Atlassian):

1. **Story actualizada** con refined acceptance criteria y label `shift-left-reviewed`
2. **Comentario agregado** con test cases completos y tags al equipo

### En Local:

1. **Archivo:** `.context/PBI/epics/EPIC-{...}/stories/STORY-{...}/test-cases.md`
2. **Contenido:** Mirror exacto del comentario en Jira

### Para Usuario:

1. **Reporte:** Resumen ejecutivo con critical questions y next steps (Paso 8)

### En Git (Branch Naming Convention):

**Formato de rama:** `test/{JIRA_ISSUE_KEY}/{short-description}`

**Ejemplos:**

- `test/UPEX-45/user-login-flow`
- `test/UPEX-123/profile-update`
- `test/UPEX-78/checkout-validation`

**Reglas:**

1. Prefijo `test/` obligatorio (indica trabajo de QA/testing)
2. Jira Issue Key en may√∫sculas (ej: UPEX-45) - extra√≠do del campo `**Jira Key:**` del story.md
3. Descripci√≥n corta en kebab-case (m√°x 3-4 palabras) - derivada del nombre de la story
4. Base branch: siempre `staging` (nunca `main`)

**‚ö†Ô∏è IMPORTANTE:**

- Esta rama SOLO debe contener cambios en archivos de documentaci√≥n de la story (test-cases.md)
- NO incluir c√≥digo de producci√≥n, configuraci√≥n de testing frameworks, ni implementaci√≥n
- El nombre de la rama debe derivarse del contexto de la story analizada

---

## üéØ FLUJO DE TRABAJO

Este prompt trabaja en **10 pasos** (Paso 0-9) organizados en 3 partes, siguiendo el principio **JIRA-FIRST ‚Üí LOCAL MIRROR**:

---

### üåø PARTE 0: PREPARACI√ìN GIT

#### Paso 0: Crear rama de trabajo

- Checkout desde `staging` y pull de cambios
- Crear rama con formato `test/{JIRA_KEY}/{short-description}`
- El Jira Key se extrae del story.md, la descripci√≥n del t√≠tulo de la story

---

### üìä PARTE 1: AN√ÅLISIS Y DISE√ëO

#### Paso 1: Critical Analysis

- Analizar la story desde perspectiva de negocio
- Identificar ambig√ºedades en acceptance criteria
- Identificar qu√© falta en la story

#### Paso 2: Story Refinement & Gap Identification

- Refinar acceptance criteria con datos espec√≠ficos
- Identificar edge cases NO mencionados en story original
- Validar que TODO sea testeable

#### Paso 3: Test Strategy Planning

- Determinar cu√°ntos test cases se necesitan realmente
- Identificar oportunidades para parametrizaci√≥n
- Planear integration/API tests si aplican

#### Paso 4: Test Design

- Generar test cases (positive, negative, boundary)
- Dise√±ar parametrized tests cuando aplique
- Dise√±ar integration/API tests basados en arquitectura

---

### üîÑ PARTE 2: INTEGRACI√ìN Y OUTPUT

#### Paso 5: Update Story in Jira

- Refinar description y acceptance criteria en Jira

#### Paso 6: Add Test Cases as Comment in Jira

- Agregar test cases completos como comentario con tags al equipo

#### Paso 7: Generate Local test-cases.md

- Crear mirror local del comentario de Jira

#### Paso 8: Final QA Feedback Report

- Generar resumen ejecutivo para el usuario

#### Paso 9: Commit del archivo test-cases.md

- Hacer commit del archivo `test-cases.md` en la rama de trabajo
- Mensaje de commit: `test({JIRA_KEY}): add shift-left test cases for {story-title}`

---

# Test Cases: STORY-{PROJECT_KEY}-{ISSUE_NUM} - [Story Title]

**Fecha:** [YYYY-MM-DD]
**QA Engineer:** [Nombre o "TBD"]
**Story Jira Key:** [{PROJECT_KEY}-{ISSUE_NUM}]
**Epic:** EPIC-{PROJECT_KEY}-{ISSUE_NUM} - [Epic Title]
**Status:** Draft | In Review | Approved

---

## üìã Paso 1: Critical Analysis

### Business Context of This Story

**User Persona Affected:**
[De User Personas, identificar qui√©n usa esta funcionalidad]

- **Primary:** [Nombre de persona] - [C√≥mo le afecta]
- **Secondary:** [Nombre de persona] - [Si aplica]

**Business Value:**
[Del Business Model y Executive Summary, explicar el valor de esta story]

- **Value Proposition:** [Qu√© valor aporta al usuario]
- **Business Impact:** [C√≥mo contribuye a KPIs del negocio]

**Related User Journey:**
[De User Journeys, identificar en qu√© journey encaja esta story]

- Journey: [Nombre del journey]
- Step: [En qu√© paso del journey est√° esta funcionalidad]

---

### Technical Context of This Story

**Architecture Components:**
[De Architecture Specs, identificar componentes involucrados]

**Frontend:**

- Components: [Listar componentes React/Vue espec√≠ficos]
- Pages/Routes: [Rutas afectadas]
- State Management: [Si aplica - Redux, Context, etc.]

**Backend:**

- API Endpoints: [Listar endpoints - seg√∫n api-contracts.yaml]
- Services: [Servicios de negocio involucrados]
- Database: [Tablas/colecciones afectadas]

**External Services:**

- [Si la story integra con servicios externos - listar]

**Integration Points:**

- [Listar puntos de integraci√≥n espec√≠ficos de esta story]

---

### Story Complexity Analysis

**Overall Complexity:** Low | Medium | High

**Complexity Factors:**

- Business logic complexity: [Low | Medium | High] - [Raz√≥n]
- Integration complexity: [Low | Medium | High] - [Raz√≥n]
- Data validation complexity: [Low | Medium | High] - [Raz√≥n]
- UI complexity: [Low | Medium | High] - [Si aplica]

**Estimated Test Effort:** [Low | Medium | High]
**Rationale:** [Explicar por qu√© este nivel de esfuerzo]

---

### Epic-Level Context (From Feature Test Plan in Jira)

**‚ö†Ô∏è IMPORTANTE:** Esta secci√≥n extrae informaci√≥n del comentario "Feature Test Plan" en el epic de Jira para proporcionar contexto actualizado.

**Critical Risks Already Identified at Epic Level:**

[Extraer del comentario del epic en Jira - secci√≥n "Critical Risks"]

- Risk 1: [Descripci√≥n del riesgo identificado a nivel epic]
  - **Relevance to This Story:** [C√≥mo este riesgo afecta espec√≠ficamente esta story]
- Risk 2: [Si aplica a esta story]
  - **Relevance to This Story:** [C√≥mo afecta]

**Integration Points from Epic Analysis:**

[Extraer del comentario del epic - secci√≥n "Integration Points"]

- Integration Point 1: [Ej: Frontend ‚Üî Backend API]
  - **Applies to This Story:** ‚úÖ Yes | ‚ùå No
  - **If Yes:** [C√≥mo esta story usa este integration point]
- Integration Point 2: [Si aplica]
  - **Applies to This Story:** ...

**Critical Questions Already Asked at Epic Level:**

[Extraer del comentario del epic - secci√≥n "Critical Questions"]

**Questions for PO:**

- Question 1: [Pregunta ya hecha a nivel epic]
  - **Status:** ‚è≥ Pending | ‚úÖ Answered | ‚ùå Not Relevant to This Story
  - **If Answered:** [Respuesta del PO - buscar en comentarios del epic]
  - **Impact on This Story:** [C√≥mo la respuesta afecta esta story]

**Questions for Dev:**

- Question 1: [Pregunta ya hecha a nivel epic]
  - **Status:** ‚è≥ Pending | ‚úÖ Answered | ‚ùå Not Relevant to This Story
  - **If Answered:** [Respuesta del Dev - buscar en comentarios del epic]
  - **Impact on This Story:** [C√≥mo la respuesta afecta esta story]

**Test Strategy from Epic:**

[Extraer del comentario del epic - secci√≥n "Test Strategy"]

- Test Levels: [Unit, Integration, E2E, API - seg√∫n epic]
- Tools: [Playwright, Vitest, etc. - seg√∫n epic]
- **How This Story Aligns:** [Explicar qu√© niveles/tools aplican a esta story espec√≠fica]

**Updates and Clarifications from Epic Refinement:**

[Si hay respuestas de PO/Dev en comentarios del epic despu√©s del test plan inicial, extraerlas aqu√≠]

- Update 1: [Clarificaci√≥n importante]
- Update 2: [Si aplica]

**Summary: How This Story Fits in Epic:**

[Sintetizar c√≥mo esta story espec√≠fica encaja en el contexto m√°s amplio del epic basado en toda la informaci√≥n anterior]

- **Story Role in Epic:** [Ej: "Esta story implementa el frontend del integration point identificado en el epic"]
- **Inherited Risks:** [Qu√© riesgos del epic aplican directamente]
- **Unique Considerations:** [Qu√© es √∫nico de esta story que NO se cubri√≥ a nivel epic]

---

## üö® Paso 2: Story Quality Analysis

### Ambiguities Identified

[Analizar story.md en detalle para identificar ambig√ºedades]

**Ambiguity 1:** [Descripci√≥n de ambig√ºedad]

- **Location in Story:** [D√≥nde est√° - acceptance criteria, description, etc.]
- **Question for PO/Dev:** [Pregunta espec√≠fica para clarificar]
- **Impact on Testing:** [Qu√© no podemos probar sin clarificar esto]
- **Suggested Clarification:** [C√≥mo deber√≠a clarificarse]

**Ambiguity 2:** [Si aplica]

- **Location in Story:** ...
- **Question for PO/Dev:** ...
- **Impact on Testing:** ...
- **Suggested Clarification:** ...

**If NO ambiguities found:** ‚úÖ Story is clear and well-defined

---

### Missing Information / Gaps

[Identificar qu√© falta en la story para poder testearse correctamente]

**Gap 1:** [Qu√© informaci√≥n falta]

- **Type:** [Acceptance Criteria | Technical Details | Business Rule | etc.]
- **Why It's Critical:** [Por qu√© lo necesitamos para testing]
- **Suggested Addition:** [Qu√© deber√≠a agregarse a la story]
- **Impact if Not Added:** [Qu√© riesgo tiene no agregarlo]

**Gap 2:** [Si aplica]

- **Type:** ...
- **Why It's Critical:** ...
- **Suggested Addition:** ...
- **Impact if Not Added:** ...

**If NO gaps found:** ‚úÖ Story has complete information for testing

---

### Edge Cases NOT Covered in Original Story

[Identificar edge cases que la story NO menciona pero son cr√≠ticos]

**Edge Case 1:** [Descripci√≥n del edge case]

- **Scenario:** [Qu√© pasa si...]
- **Expected Behavior:** [C√≥mo deber√≠a comportarse el sistema - inferir o preguntar]
- **Criticality:** High | Medium | Low
- **Action Required:** [Add to story | Add to test cases only | Ask PO]

**Edge Case 2:** [Si aplica]

- **Scenario:** ...
- **Expected Behavior:** ...
- **Criticality:** ...
- **Action Required:** ...

**If NO edge cases identified:** ‚úÖ Story covers all edge cases adequately

---

### Testability Validation

**Is this story testeable as written?** ‚úÖ Yes | ‚ö†Ô∏è Partially | ‚ùå No

**Testability Issues (if any):**

- [ ] Acceptance criteria are vague or subjective
- [ ] Expected results are not specific enough
- [ ] Missing test data examples
- [ ] Missing error scenarios
- [ ] Missing performance criteria (if NFR applies)
- [ ] Cannot be tested in isolation (missing dependencies info)

**Recommendations to Improve Testability:**
[Si hay issues, listar recomendaciones espec√≠ficas]

---

## ‚úÖ Paso 3: Refined Acceptance Criteria

[Tomar acceptance criteria del story.md y refinarlos con datos espec√≠ficos + agregar edge cases identificados]

### Scenario 1: [Nombre del escenario refinado - Happy Path]

**Type:** Positive
**Priority:** Critical

- **Given:**
  - [Estado inicial del sistema - MUY ESPEC√çFICO con datos]
  - [Precondiciones - usuario logged in como X, datos existentes Y, etc.]

- **When:**
  - [Acci√≥n del usuario - ESPEC√çFICA con datos exactos]
  - [Ej: User enters email "john@example.com" and clicks "Submit"]

- **Then:**
  - [Resultado esperado 1 - ESPEC√çFICO y VERIFICABLE]
  - [Resultado esperado 2 - con datos exactos]
  - [Resultado esperado 3 - cambios en sistema/DB]
  - [Status code esperado si es API: 200 OK]
  - [Response format esperado si es API]

---

### Scenario 2: [Error scenario - datos inv√°lidos]

**Type:** Negative
**Priority:** High

- **Given:**
  - [Estado inicial]

- **When:**
  - [Acci√≥n con datos INV√ÅLIDOS espec√≠ficos]
  - [Ej: User enters invalid email "notanemail"]

- **Then:**
  - [Mensaje de error EXACTO que debe mostrarse]
  - [Status code: 400 Bad Request]
  - [Response: {success: false, error: {code: "INVALID_EMAIL", message: "Email format is invalid"}}]
  - [Verificaci√≥n: sistema NO cambi√≥ estado/DB]

---

### Scenario 3: [Edge case - caso l√≠mite]

**Type:** Boundary
**Priority:** Medium/High

- **Given:**
  - [Estado inicial]

- **When:**
  - [Acci√≥n con valor l√≠mite - min, max, empty, etc.]

- **Then:**
  - [Comportamiento esperado espec√≠fico]

---

### Scenario 4: [Edge case adicional NO en story original]

**Type:** Edge Case
**Priority:** Medium
**Source:** Identified during critical analysis (Paso 2)

- **Given:**
  - [Estado inicial del edge case]

- **When:**
  - [Acci√≥n espec√≠fica del edge case]

- **Then:**
  - [Comportamiento esperado - NECESITA VALIDACI√ìN CON PO/DEV]
  - **‚ö†Ô∏è NOTE:** This scenario was NOT in original story - needs PO/Dev confirmation

---

[Continuar con todos los scenarios necesarios - NO forzar n√∫mero m√≠nimo]

---

## üß™ Paso 4: Test Design

### Test Coverage Analysis

**Total Test Cases Needed:** [N√∫mero realista basado en complejidad]

**Breakdown:**

- Positive: [X] test cases
- Negative: [Y] test cases
- Boundary: [Z] test cases
- Integration: [W] test cases (si aplica)
- API: [V] test cases (si la story tiene API endpoints)

**Rationale for This Number:**
[Explicar por qu√© este n√∫mero es adecuado - considerar complejidad, integration points, edge cases identificados]

---

### Parametrization Opportunities

**Parametrized Tests Recommended:** ‚úÖ Yes | ‚ùå No

**If Yes:**

**Parametrized Test Group 1:** [Nombre descriptivo]

- **Base Scenario:** [Qu√© se est√° probando]
- **Parameters to Vary:** [Qu√© datos var√≠an]
- **Test Data Sets:**

| Parameter 1 | Parameter 2 | Parameter 3 | Expected Result |
| ----------- | ----------- | ----------- | --------------- |
| [value 1]   | [value 2]   | [value 3]   | [result 1]      |
| [value 4]   | [value 5]   | [value 6]   | [result 2]      |
| [value 7]   | [value 8]   | [value 9]   | [result 3]      |

**Total Tests from Parametrization:** [N√∫mero de combinaciones]
**Benefit:** [Por qu√© parametrizar este caso - reduce duplicaci√≥n, mejor coverage, etc.]

---

**Parametrized Test Group 2:** [Si aplica]

- **Base Scenario:** ...
- **Parameters to Vary:** ...
- **Test Data Sets:** [Tabla similar]

---

**If No Parametrization:**
[Explicar por qu√© no se recomienda - ej: scenarios are too different, no common pattern, etc.]

---

### Nomenclatura de Test Outlines (Shift-Left)

**Contexto:** En Shift-Left Testing, los test cases son **Test Outlines** - gu√≠as para testing exploratorio, no test cases formales. La nomenclatura es m√°s simple que en Test Documentation (Fase 11).

**Formato:**

```
Validar <CORE> <CONDITIONAL>
```

**Definici√≥n de componentes:**

| Componente    | Qu√© es                                                                 | Ejemplos                                                                                                  |
| ------------- | ---------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- |
| `CORE`        | **El comportamiento principal** que se est√° validando (verbo + objeto) | `login exitoso`, `error de validaci√≥n`, `creaci√≥n de usuario`, `c√°lculo de total`                         |
| `CONDITIONAL` | **La condici√≥n o contexto** que hace √∫nico este escenario              | `con credenciales v√°lidas`, `cuando el campo est√° vac√≠o`, `para usuarios premium`, `al exceder el l√≠mite` |

**F√≥rmula mental:**

```
"Validar [QU√â comportamiento] [BAJO QU√â condici√≥n]"
```

**Ejemplos por tipo de test:**

| Tipo     | CORE                         | CONDITIONAL                          | T√≠tulo Completo                                                       |
| -------- | ---------------------------- | ------------------------------------ | --------------------------------------------------------------------- |
| Positive | `login exitoso`              | `con credenciales v√°lidas`           | Validar login exitoso con credenciales v√°lidas                        |
| Negative | `error de autenticaci√≥n`     | `cuando el password es incorrecto`   | Validar error de autenticaci√≥n cuando el password es incorrecto       |
| Boundary | `l√≠mite de caracteres`       | `al ingresar exactamente 50 chars`   | Validar l√≠mite de caracteres al ingresar exactamente 50 chars         |
| Edge     | `comportamiento del carrito` | `cuando hay m√∫ltiples √≠tems iguales` | Validar comportamiento del carrito cuando hay m√∫ltiples √≠tems iguales |

**Para proyectos en ingl√©s:**

```
Should <BEHAVIOR> <CONDITION>
```

| Tipo     | T√≠tulo                                                    |
| -------- | --------------------------------------------------------- |
| Positive | Should login successfully with valid credentials          |
| Negative | Should display error message when password is incorrect   |
| Boundary | Should accept exactly 50 characters in name field         |
| Edge     | Should calculate total correctly with multiple same items |

**Anti-patrones (evitar):**

| ‚ùå Incorrecto          | ‚úÖ Correcto                                            | Por qu√©                              |
| ---------------------- | ------------------------------------------------------ | ------------------------------------ |
| `Test de login`        | `Validar login exitoso con credenciales v√°lidas`       | Falta CORE espec√≠fico y CONDITIONAL  |
| `Login - error`        | `Validar error de autenticaci√≥n con password inv√°lido` | Demasiado vago, no describe contexto |
| `Probar el formulario` | `Validar env√≠o de formulario con todos los campos`     | No indica qu√© comportamiento         |
| `Caso negativo`        | `Validar rechazo de registro cuando email ya existe`   | No describe el escenario             |

**Nota:** En Fase 11 (Test Documentation), se agrega el prefijo `<TS_ID>: TC#:` para test cases formales en Jira/Xray. Ver `.context/guidelines/QA/jira-test-management.md`.

---

### Test Outlines

#### **Validar [CORE: comportamiento principal] [CONDITIONAL: condici√≥n espec√≠fica]**

**Related Scenario:** Scenario 1 (Refined AC above)
**Type:** Positive | Negative | Boundary
**Priority:** Critical | High | Medium | Low
**Test Level:** UI | API | Integration | E2E
**Parametrized:** ‚úÖ Yes (Group 1) | ‚ùå No

---

**Preconditions:**

- [Estado inicial del sistema necesario]
- [Datos pre-existentes en DB si aplica - SER ESPEC√çFICO]
- [Usuario logged in como: [role/email]]
- [Configuraci√≥n necesaria del sistema]

---

**Test Steps:**

1. [Paso 1 - acci√≥n espec√≠fica con datos exactos]
   - **Data:** Field1: "value1", Field2: "value2"
2. [Paso 2 - acci√≥n espec√≠fica]
   - **Data:** [Si aplica]
3. [Paso 3 - verificaci√≥n espec√≠fica]
   - **Verify:** [Qu√© verificar exactamente - elemento UI, response API, DB state]

---

**Expected Result:**

- **UI:** [Si aplica - qu√© debe verse, qu√© mensaje, qu√© cambio visual]
- **API Response:** [Si aplica]
  - Status Code: [200 OK | 201 Created | etc.]
  - Response Body:

    ```json
    {
      "success": true,
      "data": {
        "field1": "expected value",
        "field2": 123
      }
    }
    ```

- **Database:** [Si aplica - qu√© debe cambiar en DB]
  - Table: [tabla]
  - Record: [qu√© record se cre√≥/modific√≥/elimin√≥]
  - Fields: [campos espec√≠ficos con valores esperados]
- **System State:** [Cambios en estado del sistema]

---

**Test Data:**

```json
{
  "input": {
    "field1": "specific value",
    "field2": 123,
    "field3": true
  },
  "user": {
    "email": "testuser@example.com",
    "role": "user_role_from_PRD"
  }
}
```

---

**Post-conditions:**

- [Estado del sistema despu√©s del test]
- [Cleanup necesario si aplica]

---

#### **Validar [CORE: error/rechazo] [CONDITIONAL: condici√≥n de error]**

**Related Scenario:** Scenario 2
**Type:** Negative
**Priority:** High
**Test Level:** API
**Parametrized:** ‚ùå No

**Preconditions:**

- [Estado inicial]

**Test Steps:**

1. [Paso con datos INV√ÅLIDOS espec√≠ficos]
2. [Verificar error response]

**Expected Result:**

- **Status Code:** 400 Bad Request
- **Response Body:**

  ```json
  {
    "success": false,
    "error": {
      "code": "INVALID_INPUT",
      "message": "Email format is invalid",
      "field": "email"
    }
  }
  ```

- **Database:** NO changes (verify data was NOT created/modified)
- **UI:** [Si aplica - mensaje de error debe mostrarse]

**Test Data:**

```json
{
  "input": {
    "email": "invalid-email-format",
    "password": "Valid123!"
  }
}
```

---

#### **Validar [CORE: comportamiento l√≠mite] [CONDITIONAL: valor/condici√≥n boundary]**

**Related Scenario:** Scenario 3
**Type:** Boundary
**Priority:** Medium
**Test Level:** Integration
**Parametrized:** ‚úÖ Yes (Group 1)

[... estructura similar ...]

---

[Continuar con TODOS los test cases necesarios - tantos como se identificaron en "Test Coverage Analysis"]

---

## üîó Integration Test Cases (If Applicable)

[Si la story involucra integration points identificados en Paso 1]

### Integration Test 1: [Descripci√≥n - ej: Frontend ‚Üî Backend API]

**Integration Point:** [Frontend ‚Üí Backend API]
**Type:** Integration
**Priority:** High

**Preconditions:**

- Backend API is running
- Frontend can reach API endpoint
- [Otros pre-requisitos]

**Test Flow:**

1. Frontend sends request to API endpoint [URL]
2. API processes request
3. API returns response
4. Frontend receives and processes response

**Contract Validation:**
[Basado en api-contracts.yaml, validar contract]

- Request format matches OpenAPI spec: ‚úÖ Yes
- Response format matches OpenAPI spec: ‚úÖ Yes
- Status codes match spec: ‚úÖ Yes

**Expected Result:**

- Integration successful
- Data flows correctly: Frontend ‚Üí API ‚Üí DB ‚Üí API ‚Üí Frontend
- No data loss or transformation errors

---

### Integration Test 2: [Si aplica - ej: Backend ‚Üî External Service]

**Integration Point:** [Backend ‚Üí External Service (Stripe/Email/etc.)]
**Type:** Integration
**Priority:** High

**Mock Strategy:**

- External service will be MOCKED for automated tests
- Real integration tested manually in staging environment
- Mock tool: [MSW | Nock | etc.]

**Test Flow:**

1. [Paso de integraci√≥n]
2. [Verificaci√≥n]

**Expected Result:**

- [Resultado esperado de integraci√≥n]

---

## üìä Edge Cases Summary

[Consolidar todos los edge cases identificados]

| Edge Case     | Covered in Original Story? | Added to Refined AC?     | Test Case | Priority |
| ------------- | -------------------------- | ------------------------ | --------- | -------- |
| [Edge case 1] | ‚ùå No                      | ‚úÖ Yes (Scenario 4)      | TC-XXX    | High     |
| [Edge case 2] | ‚úÖ Yes                     | ‚úÖ Yes (Scenario 3)      | TC-YYY    | Medium   |
| [Edge case 3] | ‚ùå No                      | ‚ö†Ô∏è Needs PO confirmation | TBD       | Low      |

---

## üóÇÔ∏è Test Data Summary

### Data Categories

| Data Type       | Count | Purpose         | Examples                |
| --------------- | ----- | --------------- | ----------------------- |
| Valid data      | [X]   | Positive tests  | [Ejemplos espec√≠ficos]  |
| Invalid data    | [Y]   | Negative tests  | [Ejemplos espec√≠ficos]  |
| Boundary values | [Z]   | Boundary tests  | [min, max, empty, null] |
| Edge case data  | [W]   | Edge case tests | [Ejemplos espec√≠ficos]  |

### Data Generation Strategy

**Static Test Data:**
[Datos que se hardcodean porque son cr√≠ticos/espec√≠ficos]

- [Ejemplo 1]
- [Ejemplo 2]

**Dynamic Test Data (using Faker.js):**
[Datos que se generan din√°micamente]

- User data: `faker.internet.email()`, `faker.person.firstName()`
- Numbers: `faker.number.int({ min: X, max: Y })`
- Dates: `faker.date.recent()`

**Test Data Cleanup:**

- ‚úÖ All test data is cleaned up after test execution
- ‚úÖ Tests are idempotent (can run multiple times)
- ‚úÖ Tests do not depend on execution order

---

## üìù PARTE 2: Integraci√≥n y Output

**‚ö†Ô∏è IMPORTANTE:** Esta parte implementa el flujo **JIRA-FIRST ‚Üí LOCAL MIRROR** para mantener consistencia con el proceso de gesti√≥n de stories.

---

### Paso 5: Update Story in Jira

**Objetivo:** Refinar la story en Jira CON los refinamientos identificados en Paso 2, ANTES de generar test cases.

**Herramienta:** MCP de Atlassian

**Pasos a ejecutar:**

1. **Leer story actual de Jira:**
   - Usar MCP de Atlassian para obtener la issue
   - Input: Jira Key real extra√≠do de story.md (ej: UPEX-45)
   - ‚ö†Ô∏è **NO usar** nomenclatura de carpeta (STORY-UPEX-45)
   - Obtener: description, acceptance criteria actuales

2. **Preparar contenido refinado:**

   Basado en an√°lisis de Paso 2, preparar:
   - **Refined Acceptance Criteria** (de Paso 3)
   - **Edge Cases Identificados** (de Paso 2)
   - **Clarified Business Rules** (de Paso 2)

3. **Actualizar story en Jira:**
   - Usar MCP de Atlassian para editar la issue
   - Agregar nueva secci√≥n al description con el siguiente contenido:

   ***

   ## üß™ QA Refinements (Shift-Left Analysis)

   **Analysis Date:** [YYYY-MM-DD]
   **Status:** Refined by QA

   ### Refined Acceptance Criteria

   [Pegar refined scenarios de Paso 3]

   ### Edge Cases Identified

   [Listar edge cases de Paso 2]

   ### Clarified Business Rules

   [Agregar clarificaciones de Paso 2]

   ***
   - Agregar label: `shift-left-reviewed`

**Output esperado:**

- ‚úÖ Story actualizada en Jira con refinamientos
- ‚úÖ Label `shift-left-reviewed` agregada
- ‚úÖ Description enriquecida con an√°lisis de QA

---

### Paso 6: Add Test Cases Comment in Jira

**Objetivo:** Agregar TODOS los test cases como comentario en la story de Jira para m√°xima visibilidad del equipo.

**Herramienta:** MCP de Atlassian

**Estructura del comentario:**

```
## üß™ Shift-Left Test Cases - Generated [Date]

**QA Engineer:** [Nombre o "AI-Generated"]
**Status:** Draft - Pending PO/Dev Review

---

[PEGAR AQU√ç TODO EL CONTENIDO GENERADO DESDE "Test Cases: STORY-..." HASTA "Test Execution Tracking"]

---

## üì¢ Action Required

**@[Product Owner]:**

- [ ] Review and answer Critical Questions (see Paso 8 below)
- [ ] Validate suggested story improvements
- [ ] Confirm expected behavior for identified edge cases

**@[Dev Lead]:**

- [ ] Review Technical Questions (see Paso 8 below)
- [ ] Validate integration points and test approach
- [ ] Confirm test data strategy

**@[QA Team]:**

- [ ] Review test cases for completeness
- [ ] Validate parametrization strategy
- [ ] Prepare test environment

---

**Next Steps:**

1. Team discusses critical questions and ambiguities
2. PO/Dev provide answers and clarifications
3. QA updates test cases based on feedback
4. Dev starts implementation with clear acceptance criteria

---

**Documentation:** Full test cases also available at:
`.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/test-cases.md`
```

**Pasos a ejecutar:**

1. Usar MCP de Atlassian para agregar comentario a la issue
2. Input: Story Jira Key + contenido completo del comentario
3. Mencionar en el comentario a los miembros del equipo (@PO, @Dev, @QA) seg√∫n configuraci√≥n del proyecto

**Output esperado:**

- ‚úÖ Comentario creado en Jira con test cases completos
- ‚úÖ Equipo notificado v√≠a mentions
- ‚úÖ Checklist de acciones agregado para follow-up

---

### Paso 7: Generate Local test-cases.md (Mirroring)

**Objetivo:** Crear archivo local `.md` como MIRROR del comentario en Jira para version control y documentaci√≥n offline.

**Path:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/test-cases.md`

**Contenido:** ID√âNTICO al contenido generado en Paso 6 (todo el template de Test Cases)

**Output esperado:**

- ‚úÖ Archivo `test-cases.md` creado localmente
- ‚úÖ Contenido es MIRROR exacto del comentario en Jira
- ‚úÖ Disponible para git versioning

---

### Paso 8: Final QA Feedback Report

**Objetivo:** Reportar al USUARIO el resumen ejecutivo y acciones pendientes.

**Formato del reporte:**

---

## ‚úÖ Shift-Left Test Cases - Execution Summary

**Story:** [STORY-KEY] - [Title]
**Analysis Date:** [YYYY-MM-DD]

---

### üìä Summary for PO/Dev

**Story Quality Assessment:** ‚úÖ Good | ‚ö†Ô∏è Needs Improvement | ‚ùå Significant Issues

**Key Findings:**

1. [Finding 1 - ej: Story is clear but missing edge case X]
2. [Finding 2 - ej: Acceptance criteria should specify error messages]
3. [Finding 3 - si aplica]

---

### üö® Critical Questions for PO

[Preguntas que DEBEN responderse antes de implementaci√≥n]

**Question 1:** [Pregunta espec√≠fica sobre negocio o comportamiento]

- **Context:** [Por qu√© preguntamos esto]
- **Impact if not answered:** [Qu√© riesgo tiene]
- **Suggested Answer:** [Si tenemos sugerencia basada en user journey/business model]

**Question 2:** [Si aplica]

- **Context:** ...
- **Impact if not answered:** ...
- **Suggested Answer:** ...

---

### üîß Technical Questions for Dev

[Preguntas t√©cnicas que afectan testing approach]

**Question 1:** [Pregunta t√©cnica - ej: c√≥mo se maneja concurrencia]

- **Context:** [Por qu√© preguntamos]
- **Impact on Testing:** [C√≥mo afecta nuestros test cases]

**Question 2:** [Si aplica]

- **Context:** ...
- **Impact on Testing:** ...

---

### üí° Suggested Story Improvements

[Sugerencias para mejorar la story ANTES de implementar - basadas en an√°lisis de Paso 2]

**Improvement 1:** [Sugerencia espec√≠fica]

- **Current State:** [C√≥mo est√° ahora el acceptance criteria / description]
- **Suggested Change:** [C√≥mo deber√≠a estar]
- **Benefit:**
  - Clarity: [C√≥mo mejora claridad]
  - Testability: [C√≥mo mejora testability]
  - Quality: [C√≥mo reduce riesgos]

**Improvement 2:** [Si aplica]

- **Current State:** ...
- **Suggested Change:** ...
- **Benefit:** ...

---

### üß™ Testing Recommendations

**Pre-Implementation Testing:**

- ‚úÖ Recommended: Exploratory testing with mockups/prototypes
- ‚úÖ Recommended: Review API contracts with Dev before implementation
- [Otras recomendaciones espec√≠ficas]

**During Implementation:**

- ‚úÖ Pair with Dev for integration testing approach
- ‚úÖ Review unit tests as Dev writes them
- [Otras recomendaciones]

**Post-Implementation:**

- ‚úÖ Run all test cases designed here
- ‚úÖ Additional exploratory testing session
- ‚úÖ Performance testing (if NFRs apply)
- [Otras recomendaciones]

---

### ‚ö†Ô∏è Risks & Mitigation

[Riesgos espec√≠ficos de esta story]

**Risk 1:** [Descripci√≥n del riesgo]

- **Likelihood:** High | Medium | Low
- **Impact:** High | Medium | Low
- **Mitigation:** [Qu√© test cases mitigan este riesgo]

**Risk 2:** [Si aplica]

- **Likelihood:** ...
- **Impact:** ...
- **Mitigation:** ...

---

### ‚úÖ What Was Done

**Jira Updates:**

- ‚úÖ Story refined in Jira with acceptance criteria improvements
- ‚úÖ Label `shift-left-reviewed` added
- ‚úÖ Test cases added as comment in Jira story
- ‚úÖ Team members tagged for review (@PO, @Dev, @QA)

**Local Files:**

- ‚úÖ `test-cases.md` created at: `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/`

**Test Coverage:**

- Total test cases designed: [X]
  - Positive: [Y]
  - Negative: [Z]
  - Boundary: [W]
  - Integration: [V]

---

### üéØ Next Steps (Team Action Required)

1. **PO:** Review critical questions in Jira comment and provide answers
2. **Dev:** Review technical questions and validate test approach
3. **Team:** Discuss suggested story improvements in refinement session
4. **QA:** Wait for clarifications, then finalize test cases
5. **Dev:** Start implementation ONLY after critical questions are resolved

---

**‚ö†Ô∏è BLOCKER:** Dev should NOT start implementation until critical questions are answered by PO.

**Jira Link:** [Link to story in Jira]
**Local Test Cases:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/test-cases.md`

---

---

## üéØ Definition of Done (QA Perspective)

Esta story se considera "Done" desde QA cuando:

- [ ] All ambiguities and questions from this document are resolved
- [ ] Story is updated with suggested improvements (if accepted by PO)
- [ ] All test cases are executed and passing
- [ ] Critical/High test cases: 100% passing
- [ ] Medium/Low test cases: ‚â•95% passing
- [ ] All critical and high bugs resolved and verified
- [ ] Integration tests passing (if applicable)
- [ ] API contract validation passed (if applicable)
- [ ] NFRs validated (if applicable)
- [ ] Regression tests passed
- [ ] Exploratory testing completed
- [ ] Test execution report generated
- [ ] No blockers for next stories in epic

---

## üìé Related Documentation

- **Story:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/story.md`
- **Epic:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/epic.md`
- **Feature Test Plan:** `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/feature-test-plan.md`
- **Business Model:** `.context/idea/business-model.md`
- **PRD:** `.context/PRD/` (all files)
- **SRS:** `.context/SRS/` (all files)
- **Architecture:** `.context/SRS/architecture-specs.md`
- **API Contracts:** `.context/SRS/api-contracts.yaml`

---

## üìã Test Execution Tracking

[Esta secci√≥n se completa durante ejecuci√≥n]

**Test Execution Date:** [TBD]
**Environment:** Staging
**Executed By:** [Nombre]

**Results:**

- Total Tests: [X]
- Passed: [Y]
- Failed: [Z]
- Blocked: [W]

**Bugs Found:**

- [Bug ID 1]: [Descripci√≥n breve]
- [Bug ID 2]: [Descripci√≥n breve]

**Sign-off:** [Nombre QA] - [Fecha]

---

**Formato:** Markdown estructurado siguiendo flujo **JIRA-FIRST ‚Üí LOCAL MIRROR**

---

## üîß Prerequisitos para Ejecutar Este Prompt

- ‚úÖ TODOS los archivos de contexto (idea, PRD, SRS) deben estar completos
- ‚úÖ Feature test plan debe existir
- ‚úÖ Story.md local debe existir
- ‚úÖ **Story Path local disponible** (ej: `.context/PBI/epics/EPIC-UPEX-13-name/stories/STORY-UPEX-45-name/`)
- ‚úÖ **Story.md debe contener campo `Jira Key:`** con el key real (ej: UPEX-45)
- ‚úÖ **Epic.md debe contener campo `Jira Key:`** con el epic key real (ej: UPEX-13)
- ‚úÖ **Acceso a MCP de Atlassian configurado y funcionando**
- ‚úÖ Tiempo para analizar cr√≠ticamente y no solo generar test cases mec√°nicamente

**‚ö†Ô∏è Validaci√≥n de story.md:**

El archivo story.md debe contener en su metadata:

```markdown
**Jira Key:** UPEX-45
**Epic:** EPIC-UPEX-13-feature-name
```

Estos son los datos reales. Nota: El n√∫mero de issue (45, 13) es el mismo en la nomenclatura de carpeta y en el Jira Key.

---

## üìã Flujo de Ejecuci√≥n (Para la IA)

### Paso 0: Crear rama de trabajo

**Objetivo:** Crear una rama espec√≠fica para el trabajo de Shift-Left Testing antes de generar los test cases.

**Pasos a ejecutar:**

1. Checkout desde `staging`: `git checkout staging && git pull`
2. Crear rama usando el formato: `test/{JIRA_KEY}/{short-description}`
3. El `{JIRA_KEY}` se extrae del campo `**Jira Key:**` del story.md
4. El `{short-description}` se deriva del nombre/t√≠tulo de la story en kebab-case (m√°x 3-4 palabras)

**Ejemplo:**

```bash
git checkout staging && git pull
git checkout -b test/UPEX-45/user-login-flow
```

**‚ö†Ô∏è IMPORTANTE:** Esta rama solo contendr√° el archivo `test-cases.md` generado. NO incluir otros cambios.

---

### Input requerido del usuario:

```
Story Path: .context/PBI/epics/EPIC-UPEX-13-nombre/stories/STORY-UPEX-45-nombre/
```

**‚ö†Ô∏è Proceso Autom√°tico:**

1. Prompt lee: `{STORY_PATH}/story.md`
2. Prompt extrae: Campo `**Jira Key:**` (ej: UPEX-45)
3. Prompt extrae: Campo `**Epic:**` para encontrar epic path
4. Prompt lee: Epic.md y extrae Epic Jira Key (ej: UPEX-13)
5. Prompt usa: Jira Keys reales para operaciones MCP

### Orden de ejecuci√≥n:

**Paso 0: Crear rama de trabajo**

1. Leer `{STORY_PATH}/story.md` proporcionado por usuario
2. Extraer campo `**Jira Key:**` de story (ej: UPEX-45)
3. Derivar `{short-description}` del t√≠tulo de la story en kebab-case
4. Ejecutar: `git checkout staging && git pull`
5. Crear rama: `git checkout -b test/{JIRA_KEY}/{short-description}`

**Pre-requisito: Extraer Jira Keys** 6. Extraer campo `**Epic:**` para obtener epic path 7. Leer epic.md y extraer Epic Jira Key (ej: UPEX-13) 8. Guardar ambos Jira Keys reales para Pasos 5 y 6

**Leer Contexto Completo:** 9. Leer todos los archivos de contexto (PRD, SRS, epic.md local, feature-test-plan.md, story.md) 10. Leer story actual de Jira con MCP (usando Story Jira Key real) 11. Leer epic de Jira con MCP (usando Epic Jira Key real) 12. **Leer comentarios del epic en Jira** - especialmente "Feature Test Plan"

**PARTE 1 - An√°lisis y Dise√±o:** 13. **Paso 1:** Critical Analysis (incluye Epic-Level Context de comentarios) 14. **Paso 2:** Story Quality Analysis 15. **Paso 3:** Refined Acceptance Criteria 16. **Paso 4:** Test Design

**PARTE 2 - Integraci√≥n y Output:** 17. **Paso 5:** Actualizar story en Jira con refinamientos (MCP + Story Jira Key real) 18. **Paso 6:** Crear comentario en Jira con test cases completos (MCP + Story Jira Key real) 19. **Paso 7:** Generar archivo local `test-cases.md` en {STORY_PATH}/ (Write tool) 20. **Paso 8:** Reportar resumen al usuario (Output) 21. **Paso 9:** Commit del archivo `test-cases.md` en la rama de trabajo

### Herramientas a usar:

**Git (Bash):**

- Para checkout de `staging` y pull de cambios recientes
- Para crear rama de trabajo con formato `test/{JIRA_KEY}/{short-description}`
- Para commit del archivo `test-cases.md` generado

**MCP de Atlassian:**

- Para leer story de Jira
- Para leer epic de Jira (description actualizado)
- **Para leer comentarios del epic en Jira** (especialmente "Feature Test Plan")
- Para actualizar story description y labels
- Para agregar comentarios a issues

**File Operations:**

- Para crear archivo local test-cases.md
- Para leer archivos de contexto (PRD, SRS, epic, feature-test-plan, story.md)

---

## ‚ö†Ô∏è IMPORTANTE: Principios de Ejecuci√≥n

### Shift-Left Testing Philosophy:

- ‚úÖ **An√°lisis cr√≠tico primero, test design despu√©s**
- ‚úÖ **Feedback temprano es M√ÅS valioso que test cases perfectos**
- ‚úÖ **Refinar la story ANTES de implementaci√≥n** (shift-left!)
- ‚úÖ **Test cases exploratorios = comentarios en Jira** (no incidencias separadas)
- ‚úÖ **Contexto epic es cr√≠tico** - SIEMPRE leer comentarios del epic en Jira para obtener:
  - Riesgos ya identificados
  - Preguntas ya respondidas por PO/Dev
  - Integration points cr√≠ticos
  - Updates posteriores al test plan inicial

### Test Design Guidelines:

- ‚ùå **NO forzar n√∫mero m√≠nimo de test cases** - depende de complejidad
- ‚úÖ **Usar parametrizaci√≥n cuando aplique** - reduce duplicaci√≥n
- ‚úÖ **Identificar edge cases NO cubiertos** en story original
- ‚úÖ **Hacer preguntas cr√≠ticas a PO/Dev** - mejor clarificar que asumir

### Jira-First Workflow:

- ‚úÖ **SIEMPRE actualizar Jira primero, luego local** (consistencia con flujo de stories)
- ‚úÖ **Test cases van en comentarios, NO en subtareas** (naturaleza exploratoria)
- ‚úÖ **Taggear al equipo** (@PO, @Dev, @QA) para visibilidad
- ‚úÖ **Agregar label `shift-left-reviewed`** para tracking

---

## üéØ Post-Generaci√≥n: Acciones del Equipo

### Inmediatamente despu√©s de ejecutar este prompt:

1. **PO debe:**
   - Revisar comentario en Jira con test cases
   - Responder "Critical Questions for PO" en Paso 8
   - Validar "Suggested Story Improvements"
   - Confirmar expected behavior de edge cases identificados

2. **Dev debe:**
   - Revisar comentario en Jira con test cases
   - Responder "Technical Questions for Dev" en Paso 8
   - Validar integration points y test approach
   - **NO empezar implementaci√≥n** hasta resolver preguntas cr√≠ticas

3. **QA debe:**
   - Esperar respuestas de PO/Dev
   - Actualizar test cases basado en feedback
   - Preparar test environment

4. **Usuario (quien ejecut√≥ el prompt) debe:**
   - Compartir link de Jira story con equipo
   - Facilitar discusi√≥n de preguntas cr√≠ticas
   - Asegurar que preguntas sean respondidas antes de sprint

---

## üöÄ Evoluci√≥n de Test Cases (Post Shift-Left)

### Opciones para formalizar test cases:

Una vez que PO/Dev han clarificado todas las preguntas y la story est√° refinada:

**Opci√≥n A: Mantener en comentarios** (Recomendado para stories simples)

- Test cases quedan en comentario de Jira
- Archivo local sirve como documentaci√≥n
- QA ejecuta desde archivo local o comentario

**Opci√≥n B: Migrar a Xray/Zephyr** (Para stories complejas o cr√≠ticas)

- Crear Test Set/Suite en herramienta de gesti√≥n de tests
- Linkear con story usando "IsTestedBy"
- Mantener archivo local como mirror

**Opci√≥n C: Automatizar** (Una vez test cases son estables)

- Usar test cases como base para automation scripts
- Generar tests con Playwright/Cypress basados en test-cases.md
- Integrar a CI/CD pipeline

---

## üîÑ Workflow Integrado: Epic ‚Üî Story Context

### Flujo de Informaci√≥n:

```
1. Epic Test Plan generado ‚Üí Comentario en Epic (Jira)
                           ‚Üì
2. PO/Dev responden preguntas en comentarios del Epic
                           ‚Üì
3. Story Test Cases lee comentarios del Epic
                           ‚Üì
4. Story Test Cases hereda contexto:
   - Riesgos identificados
   - Preguntas ya respondidas
   - Integration points
   - Test strategy
                           ‚Üì
5. Story Test Cases enfoca en gaps espec√≠ficos de la story
                           ‚Üì
6. Comentario agregado a Story (Jira) con test cases
                           ‚Üì
7. PO/Dev responden preguntas espec√≠ficas de la story
                           ‚Üì
8. Implementaci√≥n comienza con contexto completo
```

**Beneficios de este flujo:**

- ‚úÖ **Evita duplicaci√≥n** de preguntas entre epic y stories
- ‚úÖ **Contexto acumulativo** - cada story hereda conocimiento del epic
- ‚úÖ **Trazabilidad completa** - todo est√° documentado en Jira comments
- ‚úÖ **Colaboraci√≥n mejorada** - PO/Dev ven evoluci√≥n del an√°lisis
- ‚úÖ **Decisiones informadas** - Dev implementa con contexto completo de riesgos

---

## üìö Filosof√≠a CATA (Component-Action-Test-Architecture)

Este prompt sigue principios CATA:

- **Component:** Stories en Jira + archivos .md locales
- **Action:** Shift-Left Testing - an√°lisis y refinamiento temprano
- **Test:** Test cases exploratorios en comentarios ‚Üí formalizaci√≥n posterior
- **Architecture:** Jira-First ‚Üí Local Mirror ‚Üí Version Control ‚Üí Automation (eventual)

**Trazabilidad:**

```
Epic (Jira)
  ‚Üì contains
Story (Jira + .md)
  ‚Üì IsTestedBy (via comment)
Test Cases (Comment + test-cases.md)
  ‚Üì eventually migrates to
Test Suite (Xray/Zephyr - opcional)
  ‚Üì automates to
Test Scripts (Playwright/Cypress - opcional)
```

---

**Versi√≥n:** 3.2 - Git Branch Naming Convention + Paso 0
**√öltima actualizaci√≥n:** 2025-12-06
**Cambios principales:**

- ‚úÖ Agregado flujo Jira-First (Pasos 5-8)
- ‚úÖ Integraci√≥n con MCP de Atlassian
- ‚úÖ Test cases en comentarios (no subtareas)
- ‚úÖ Refinamiento autom√°tico de story en Jira
- ‚úÖ Filosof√≠a CATA integrada
- ‚úÖ **Lectura de comentarios del epic en Jira** para contexto actualizado
- ‚úÖ **Nueva sub-secci√≥n "Epic-Level Context"** en Paso 1 que extrae:
  - Riesgos cr√≠ticos identificados a nivel epic
  - Integration points del epic analysis
  - Preguntas cr√≠ticas ya hechas y respondidas
  - Test strategy del epic
  - Updates y clarificaciones del refinement
  - C√≥mo la story encaja en el epic
- ‚úÖ **Branch Naming Convention para Git** - formato `test/{JIRA_KEY}/{short-description}`
- ‚úÖ **Paso 0: Crear rama de trabajo** - checkout desde `staging` antes de generar test cases
- ‚úÖ **Paso 9: Commit del archivo** - commit del `test-cases.md` en la rama de trabajo
