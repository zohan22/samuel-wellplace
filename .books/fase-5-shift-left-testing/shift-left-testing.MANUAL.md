<!-- MANUAL PARA HUMANOS - No es un prompt para IA -->

# Shift-Left Testing - Manual

> **Fase:** 5 - Shift-Left Testing (Testing Temprano)
> **Tiempo estimado:** 2-4 horas por Ã©pica + 30-60 min por story
> **Herramientas:** Jira, Markdown, Git, PRD/SRS como referencia
> **Pre-requisito:** Fase 4 (Specification) completada con Ã©picas y stories

---

## Objetivo

Ejecutar **testing antes de que exista cÃ³digo**:

1. **Feature Test Plan:** AnÃ¡lisis y estrategia de testing a nivel Ã©pica
2. **Story Test Cases:** Test cases especÃ­ficos por cada user story
3. **Feedback Temprano:** Identificar problemas, ambigÃ¼edades y riesgos ANTES de implementar

El principio fundamental: **encontrar defectos es mÃ¡s barato cuanto antes los encuentres**.

---

## Conceptos Clave

### ðŸ”‘ Shift-Left Testing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SHIFT-LEFT PHILOSOPHY                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  TRADICIONAL:                                                    â”‚
â”‚                                                                  â”‚
â”‚  Requirements â†’ Design â†’ Code â†’ Test â†’ Deploy                   â”‚
â”‚                                         â†‘                        â”‚
â”‚                                    Testing here                  â”‚
â”‚                                    (late, expensive)             â”‚
â”‚                                                                  â”‚
â”‚  SHIFT-LEFT:                                                     â”‚
â”‚                                                                  â”‚
â”‚  Requirements â†’ Design â†’ Code â†’ Test â†’ Deploy                   â”‚
â”‚       â†‘             â†‘                                            â”‚
â”‚  Testing here   Testing here                                     â”‚
â”‚  (early, cheap) (integration)                                    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Por quÃ© funciona:**

- **Costo 1x:** Encontrar bug en requirements
- **Costo 10x:** Encontrar bug en desarrollo
- **Costo 100x:** Encontrar bug en producciÃ³n

### ðŸ”‘ Feature Test Plan vs Story Test Cases

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  EPIC: User Authentication                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚          FEATURE TEST PLAN                             â”‚      â”‚
â”‚  â”‚                                                        â”‚      â”‚
â”‚  â”‚  â€¢ Risk Analysis (technical, business, integration)   â”‚      â”‚
â”‚  â”‚  â€¢ Test Strategy (levels, types, tools)               â”‚      â”‚
â”‚  â”‚  â€¢ Test Scope (in/out of scope)                       â”‚      â”‚
â”‚  â”‚  â€¢ Entry/Exit Criteria                                â”‚      â”‚
â”‚  â”‚  â€¢ NFR Validation Plan                                â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                          â”‚                                       â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â–¼                    â–¼                    â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ STORY 1   â”‚     â”‚ STORY 2   â”‚     â”‚ STORY 3   â”‚              â”‚
â”‚  â”‚ Signup    â”‚     â”‚ Login     â”‚     â”‚ Password  â”‚              â”‚
â”‚  â”‚           â”‚     â”‚           â”‚     â”‚ Reset     â”‚              â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚
â”‚  â”‚ â”‚Test   â”‚ â”‚     â”‚ â”‚Test   â”‚ â”‚     â”‚ â”‚Test   â”‚ â”‚              â”‚
â”‚  â”‚ â”‚Cases  â”‚ â”‚     â”‚ â”‚Cases  â”‚ â”‚     â”‚ â”‚Cases  â”‚ â”‚              â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Feature Test Plan:** Vista macro, riesgos globales, estrategia general
- **Story Test Cases:** Vista micro, test cases especÃ­ficos, datos concretos

### ðŸ”‘ Tipos de Test Cases

| Tipo            | PropÃ³sito                 | Ejemplo                                     |
| --------------- | ------------------------- | ------------------------------------------- |
| **Positive**    | Happy path, flujo exitoso | Login con credenciales vÃ¡lidas              |
| **Negative**    | Errores y validaciones    | Login con password incorrecto               |
| **Boundary**    | Valores lÃ­mite            | Email con exactamente 254 caracteres        |
| **Edge Case**   | Escenarios inusuales      | Login con sesiÃ³n activa en otro dispositivo |
| **Integration** | Puntos de integraciÃ³n     | Frontend â†’ API â†’ Database                   |

### ðŸ”‘ Gherkin Format

Formato estÃ¡ndar para escribir acceptance criteria y test cases:

```gherkin
Scenario: [Nombre descriptivo del escenario]

Given [Contexto inicial / precondiciones]
  And [PrecondiciÃ³n adicional]
When [AcciÃ³n del usuario]
  And [AcciÃ³n adicional]
Then [Resultado esperado]
  And [VerificaciÃ³n adicional]
```

**Ejemplo concreto:**

```gherkin
Scenario: Successful login with valid credentials

Given I am on the login page
  And I have an active account with email "user@example.com"
When I enter email "user@example.com"
  And I enter password "SecurePass123!"
  And I click the "Login" button
Then I should be redirected to "/dashboard"
  And I should see "Welcome back" message
  And my session should be active for 7 days
```

---

## Pre-requisitos

### DocumentaciÃ³n Lista

- [ ] `.context/PRD/` - Product Requirements Document completo
- [ ] `.context/SRS/` - Software Requirements Specification completo
- [ ] `.context/PBI/epics/EPIC-XXX/epic.md` - Ã‰pica documentada
- [ ] `.context/PBI/epics/EPIC-XXX/stories/STORY-YYY/story.md` - Stories documentadas

### Jira Configurado

- [ ] Ã‰pica existe en Jira con ID real
- [ ] Stories existen en Jira vinculadas a la Ã©pica
- [ ] Permisos para comentar y editar issues

---

# PARTE 1: FEATURE TEST PLAN (Nivel Ã‰pica)

## Paso 1: Analizar Contexto de Negocio

Antes de pensar en tests, entiende el **valor de negocio** de la Ã©pica.

### 1.1 Revisar Business Model Canvas

Abre `.context/idea/business-model.md` y responde:

- Â¿QuÃ© **Value Proposition** habilita esta Ã©pica?
- Â¿QuÃ© **segmentos de clientes** se benefician?
- Â¿QuÃ© **revenue stream** impacta?

### 1.2 Revisar User Personas

Abre `.context/PRD/user-personas.md` y responde:

- Â¿QuÃ© personas usan esta funcionalidad?
- Â¿CuÃ¡les son sus goals y pain points?
- Â¿QuÃ© nivel de expertise tÃ©cnico tienen?

### 1.3 Revisar User Journeys

Abre `.context/PRD/user-journeys.md` y responde:

- Â¿QuÃ© journeys habilita o modifica esta Ã©pica?
- Â¿En quÃ© paso del journey encaja?
- Â¿QuÃ© pasa si falla en este punto del journey?

### 1.4 Documentar Business Context

```markdown
## Business Context Analysis

### Business Value

- **Value Proposition:** [QuÃ© valor aporta al usuario]
- **Business Impact:** [CÃ³mo contribuye a KPIs]

### User Impact

- **Primary User:** [Persona X] - [CÃ³mo le afecta]
- **Secondary User:** [Persona Y] - [CÃ³mo le afecta]

### Critical User Journeys

- [Journey 1] - Step [X]
- [Journey 2] - Step [Y]
```

---

## Paso 2: Analizar Contexto TÃ©cnico

Entiende la **arquitectura** involucrada en esta Ã©pica.

### 2.1 Revisar Architecture Specs

Abre `.context/SRS/architecture-specs.md` e identifica:

**Frontend:**

- Componentes a crear/modificar
- PÃ¡ginas/rutas afectadas
- State management involucrado

**Backend:**

- APIs a crear/modificar
- Servicios de negocio afectados
- Tablas de base de datos involucradas

**Servicios Externos:**

- Integraciones con terceros (payments, email, etc.)
- APIs externas consumidas

### 2.2 Revisar API Contracts

Abre `.context/SRS/api-contracts.yaml` e identifica:

- Endpoints que esta Ã©pica crea/modifica
- Request/Response formats
- Status codes esperados
- AutenticaciÃ³n/autorizaciÃ³n requerida

### 2.3 Identificar Integration Points

**Integration Points** son los lugares donde diferentes sistemas se comunican:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTEGRATION POINTS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  INTERNOS:                                                       â”‚
â”‚  â€¢ Frontend â†” Backend API                                        â”‚
â”‚  â€¢ Backend â†” Database                                            â”‚
â”‚  â€¢ Backend â†” Auth Service                                        â”‚
â”‚  â€¢ Backend â†” File Storage                                        â”‚
â”‚                                                                  â”‚
â”‚  EXTERNOS:                                                       â”‚
â”‚  â€¢ Backend â†” Payment Provider (Stripe, etc.)                    â”‚
â”‚  â€¢ Backend â†” Email Service (SendGrid, etc.)                     â”‚
â”‚  â€¢ Backend â†” Third-party APIs                                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Por quÃ© importan:** Los integration points son donde mÃ¡s bugs ocurren.

### 2.4 Documentar Technical Context

```markdown
## Technical Architecture Analysis

### Architecture Components Involved

**Frontend:**

- Components: [Button, Form, Modal, ...]
- Pages: [/signup, /login, /dashboard]
- State: [AuthContext, user state]

**Backend:**

- APIs: [POST /auth/signup, POST /auth/login]
- Services: [AuthService, UserService]
- Database: [profiles table, sessions table]

**External Services:**

- [Supabase Auth]
- [Email service for verification]

### Integration Points (Critical for Testing)

1. Frontend â†” Backend Auth API
2. Backend â†” Supabase Auth
3. Backend â†” Database (profiles table)
4. Backend â†” Email Service (verification emails)
```

---

## Paso 3: Risk Analysis

Identifica quÃ© puede salir mal y cÃ³mo mitigarlo.

### 3.1 Identificar Riesgos TÃ©cnicos

Para cada componente tÃ©cnico, pregÃºntate:

- **Performance:** Â¿Puede ser lento? Â¿Hay operaciones costosas?
- **Security:** Â¿Hay datos sensibles? Â¿Puntos de entrada de ataques?
- **Scalability:** Â¿QuÃ© pasa con muchos usuarios concurrentes?
- **Reliability:** Â¿QuÃ© pasa si un servicio externo falla?

### 3.2 Identificar Riesgos de Negocio

- **User Experience:** Â¿Puede frustrar al usuario?
- **Data Integrity:** Â¿Puede perderse o corromperse data?
- **Revenue Impact:** Â¿Puede afectar ingresos?
- **Reputation:** Â¿Puede daÃ±ar la imagen de la empresa?

### 3.3 Identificar Riesgos de IntegraciÃ³n

Para cada integration point:

- Â¿QuÃ© pasa si falla la conexiÃ³n?
- Â¿QuÃ© pasa si la respuesta es lenta?
- Â¿QuÃ© pasa si el formato de datos cambia?

### 3.4 Documentar Risks

```markdown
## Risk Analysis

### Technical Risks

**Risk 1:** Password storage compromise

- **Impact:** High
- **Likelihood:** Low (if bcrypt used correctly)
- **Area:** Security
- **Mitigation:**
  - Validate bcrypt implementation
  - Test for SQL injection
  - Verify HTTPS enforcement
- **Test Coverage:** Security test cases, penetration testing

**Risk 2:** Session hijacking

- **Impact:** High
- **Likelihood:** Medium
- **Area:** Security
- **Mitigation:**
  - Validate JWT implementation
  - Test token expiration
  - Test secure cookie flags
- **Test Coverage:** Auth flow tests, session management tests

### Business Risks

**Risk 1:** User abandonment during signup

- **Impact:** Lost conversion, lost revenue
- **Likelihood:** High (if UX is poor)
- **Mitigation:**
  - Test form validation UX
  - Test error message clarity
  - Test mobile experience
- **Test Coverage:** UX tests, mobile tests

### Integration Risks

**Risk 1:** Email service failure during signup

- **Impact:** User can't verify email, can't use app
- **Likelihood:** Low
- **Mitigation:**
  - Implement retry logic
  - Allow manual verification fallback
- **Test Coverage:** Integration tests with mocked email, fallback tests
```

---

## Paso 4: Critical Analysis & Questions

Revisa las Ã©picas y stories buscando **ambigÃ¼edades** y **gaps**.

### 4.1 Revisar Epic y Stories

Lee cada story de la Ã©pica y pregÃºntate:

- Â¿El acceptance criteria es especÃ­fico o vago?
- Â¿Los resultados esperados son verificables?
- Â¿QuÃ© pasa si [escenario de error]?
- Â¿Hay edge cases no mencionados?

### 4.2 Identificar AmbigÃ¼edades

**AmbigÃ¼edad:** Algo que puede interpretarse de mÃ¡s de una manera.

**Ejemplo de ambigÃ¼edad:**

```
âŒ Vago: "El usuario debe poder iniciar sesiÃ³n fÃ¡cilmente"
         â†‘
         Â¿QuÃ© significa "fÃ¡cilmente"? Â¿En cuÃ¡ntos clicks?

âœ… Claro: "El usuario completa el login en mÃ¡ximo 2 pasos:
          1. Ingresar email y password
          2. Click en Login button
          El proceso toma menos de 10 segundos."
```

### 4.3 Identificar Missing Information

**Ejemplos de informaciÃ³n faltante:**

- Mensaje de error exacto cuando password es incorrecto
- Tiempo mÃ¡ximo de sesiÃ³n activa
- Comportamiento cuando hay sesiÃ³n activa en otro dispositivo
- LÃ­mite de intentos fallidos de login

### 4.4 Generar Preguntas para PO/Dev

Convierte cada ambigÃ¼edad en una pregunta especÃ­fica:

```markdown
## Critical Questions for Team

### Questions for PO (Product Owner)

**Q1:** Â¿CuÃ¡l es el mensaje exacto cuando el password es incorrecto?

- **Context:** Story STORY-XX no especifica mensajes de error
- **Impact if not clarified:** Podemos implementar mensaje genÃ©rico que confunda al usuario
- **Suggested Answer:** "Incorrect password. Please try again."

**Q2:** Â¿QuÃ© pasa si el usuario tiene sesiÃ³n activa en otro dispositivo?

- **Context:** No estÃ¡ claro si permitimos mÃºltiples sesiones
- **Impact if not clarified:** PodrÃ­amos tener inconsistencias de datos
- **Suggested Answer:** Invalidar sesiÃ³n anterior al hacer nuevo login

### Questions for Dev (Developer)

**Q1:** Â¿CÃ³mo manejamos rate limiting en el endpoint de login?

- **Context:** Necesitamos proteger contra brute force attacks
- **Impact on Testing:** Necesito saber los lÃ­mites para diseÃ±ar test cases
- **Suggested Answer:** 5 intentos por minuto, luego lockout de 15 minutos
```

---

## Paso 5: Define Test Strategy

Con todo el anÃ¡lisis previo, define la estrategia de testing.

### 5.1 Define Test Scope

```markdown
## Test Scope

### In Scope

- Functional testing (UI, API, Database)
- Integration testing (internal + external services)
- Security testing (auth, injection, XSS)
- Performance testing (page load, API response time)
- Cross-browser (Chrome, Firefox, Safari)
- Mobile responsiveness (iOS, Android)

### Out of Scope (For This Epic)

- Load testing extremo (1000+ usuarios concurrentes)
- Penetration testing profesional (contratado aparte)
- Accessibility testing profundo (cubierto en epic especÃ­fico)
```

### 5.2 Define Test Levels

```markdown
## Test Levels

### Unit Testing

- **Goal:** >80% code coverage
- **Focus:** Validation functions, auth utilities
- **Responsibility:** Dev team (QA validates existence)

### Integration Testing

- **Goal:** All integration points covered
- **Focus:**
  - Frontend â†” Backend API
  - Backend â†” Database
  - Backend â†” External Services (mocked)
- **Responsibility:** QA + Dev (pair testing)

### End-to-End Testing

- **Goal:** Critical user journeys covered
- **Tool:** Playwright
- **Focus:**
  - Complete signup flow
  - Complete login flow
  - Password reset flow
- **Responsibility:** QA team

### API Testing

- **Goal:** 100% endpoints covered
- **Tool:** Postman/Newman or Playwright API
- **Focus:**
  - Contract validation (OpenAPI spec)
  - Status codes
  - Error handling
  - Authentication
- **Responsibility:** QA team
```

### 5.3 Define Entry/Exit Criteria

```markdown
## Entry/Exit Criteria

### Entry Criteria (Testing Can Start When)

- [ ] Story deployed to staging
- [ ] Code review approved
- [ ] Unit tests passing (>80% coverage)
- [ ] Dev smoke testing done
- [ ] Test data available

### Exit Criteria (Story Done When)

- [ ] All test cases executed
- [ ] Critical/High tests: 100% passing
- [ ] Medium/Low tests: â‰¥95% passing
- [ ] All Critical/High bugs resolved
- [ ] Regression tests passing
- [ ] NFRs validated
```

---

## Paso 6: Estimate Test Cases

Estima cuÃ¡ntos test cases necesitas por story.

### 6.1 Analyze Story Complexity

Para cada story, evalÃºa:

| Factor             | Low                | Medium         | High                 |
| ------------------ | ------------------ | -------------- | -------------------- |
| Business Logic     | Simple validations | Multiple rules | Complex calculations |
| Integration Points | None               | 1-2 points     | 3+ points            |
| Data Validations   | 1-3 fields         | 4-6 fields     | 7+ fields            |
| Error Scenarios    | 1-2 cases          | 3-5 cases      | 6+ cases             |
| UI Complexity      | 1 form             | Multiple forms | Complex UI           |

### 6.2 Estimate Per Story

```markdown
## Test Cases Summary by Story

### STORY-MYM-3: Signup with Email

**Complexity:** Medium
**Estimated Test Cases:** 8

- Positive: 2 (happy path, variations)
- Negative: 3 (invalid email, weak password, existing email)
- Boundary: 2 (min/max password length, email length)
- Integration: 1 (email verification flow)

**Rationale:** Signup has multiple validations and email integration.

### STORY-MYM-4: Login

**Complexity:** Medium
**Estimated Test Cases:** 6

- Positive: 1 (successful login)
- Negative: 3 (wrong password, non-existent user, unverified email)
- Boundary: 1 (session timeout)
- Integration: 1 (session management)

**Rationale:** Fewer fields but critical security implications.
```

---

## Paso 7: Document and Share Test Plan

### 7.1 Create feature-test-plan.md

Consolida todo en un archivo:

```
.context/PBI/epics/EPIC-MYM-2-user-authentication/feature-test-plan.md
```

Incluye todas las secciones que documentaste.

### 7.2 Add to Jira Epic

1. Abre la Ã©pica en Jira
2. Edita la descripciÃ³n
3. Agrega secciÃ³n:

```markdown
---

## ðŸ§ª QA Test Strategy - Shift-Left Analysis

**Analysis Date:** [YYYY-MM-DD]
**Status:** Test Plan Ready

### Critical Risks Identified
1. [Risk 1 - resumen]
2. [Risk 2 - resumen]
3. [Risk 3 - resumen]

### Test Coverage Summary
- **Total Estimated Test Cases:** [X]
- **Integration Points:** [Y]
- **Critical User Journeys:** [Z]

### Critical Questions
See comment below for full list.

---
```

4. Agrega label: `test-plan-ready`

### 7.3 Add Comment with Full Test Plan

Agrega un comentario a la Ã©pica con:

- Test plan completo
- Preguntas para PO/Dev
- Taggea a los miembros del equipo (@PO, @Dev, @QA)

---

# PARTE 2: STORY TEST CASES (Nivel Story)

## Paso 8: Select Story

Elige la story a analizar. Generalmente en orden de dependencias.

### 8.1 Read Story Completely

Abre el `story.md` y lee:

- User Story (As a... I want to... So that...)
- Description
- Acceptance Criteria
- Technical Notes
- Dependencies

### 8.2 Review Feature Test Plan

Revisa el `feature-test-plan.md` de la Ã©pica para contexto:

- Â¿QuÃ© riesgos aplican a esta story?
- Â¿QuÃ© integration points afectan a esta story?
- Â¿QuÃ© preguntas del epic aplican aquÃ­?

---

## Paso 9: Critical Analysis of Story

### 9.1 Identify Ambiguities

Lee cada acceptance criteria y pregunta:

- Â¿Es especÃ­fico? Â¿Puedo verificarlo objetivamente?
- Â¿QuÃ© datos exactos se usan?
- Â¿QuÃ© mensaje exacto se muestra?

**Ejemplo:**

```
Original Acceptance Criteria:
"When user enters invalid email, show error message"
               â†‘
               Ambiguo: Â¿QuÃ© mensaje? Â¿DÃ³nde se muestra?

Refined:
"When user enters invalid email format (e.g., 'notanemail')
 Then display error message 'Please enter a valid email address'
 And the error should appear below the email field
 And the email field should have red border"
               â†‘
               EspecÃ­fico: Mensaje exacto, ubicaciÃ³n, estilo
```

### 9.2 Identify Missing Information

Lista quÃ© falta:

```markdown
## Missing Information

**Gap 1:** No se especifica el formato del error response de la API

- **Why Critical:** Necesito saber quÃ© validar en API tests
- **Suggested:** { "error": { "code": "INVALID_EMAIL", "message": "..." } }

**Gap 2:** No se especifica timeout de sesiÃ³n

- **Why Critical:** Necesito testear comportamiento al expirar
- **Suggested:** 7 dÃ­as de inactividad
```

### 9.3 Identify Edge Cases

Piensa en escenarios que la story NO menciona:

```markdown
## Edge Cases NOT in Story

**Edge Case 1:** User submits form twice (double-click)

- **Expected Behavior:** Should prevent duplicate submissions
- **Criticality:** Medium
- **Action:** Add to test cases, ask Dev about implementation

**Edge Case 2:** Network disconnection during submit

- **Expected Behavior:** Show offline message, retry option
- **Criticality:** Medium
- **Action:** Ask PO about expected behavior

**Edge Case 3:** Browser back button after successful login

- **Expected Behavior:** Should not show login form again
- **Criticality:** Low
- **Action:** Add to test cases
```

---

## Paso 10: Refine Acceptance Criteria

Reescribe los acceptance criteria con datos especÃ­ficos.

### 10.1 Add Specific Data

```gherkin
# BEFORE (vago)
Scenario: Successful signup
Given I am on signup page
When I enter valid email and password
Then I should be registered

# AFTER (especÃ­fico)
Scenario: Successful signup with valid credentials
Given I am on the "/signup" page
  And no account exists with email "newuser@example.com"
When I enter email "newuser@example.com"
  And I enter password "SecurePass123!"
  And I click "Create Account" button
Then I should see a loading indicator for < 3 seconds
  And I should see message "Account created! Check your email to verify."
  And I should be redirected to "/verify-email"
  And a new record should exist in "profiles" table with email "newuser@example.com"
  And a verification email should be sent to "newuser@example.com"
```

### 10.2 Add Error Scenarios

```gherkin
Scenario: Signup with invalid email format
Given I am on the "/signup" page
When I enter email "notanemail"
  And I try to submit the form
Then I should see error message "Please enter a valid email address"
  And the error should appear below the email field
  And the email field should have class "error"
  And the form should NOT be submitted
  And NO record should be created in database
```

### 10.3 Add Boundary Scenarios

```gherkin
Scenario: Signup with password at minimum length (8 characters)
Given I am on the "/signup" page
When I enter email "user@example.com"
  And I enter password "Pass123!" (exactly 8 characters)
Then the signup should succeed

Scenario: Signup with password below minimum length (7 characters)
Given I am on the "/signup" page
When I enter email "user@example.com"
  And I enter password "Pass12!" (only 7 characters)
Then I should see error "Password must be at least 8 characters"
```

---

## Paso 11: Design Test Cases

Convierte los scenarios en test cases ejecutables.

### 11.1 Test Case Structure

````markdown
### TC-01: Validar signup exitoso con credenciales vÃ¡lidas

**Type:** Positive
**Priority:** Critical
**Test Level:** E2E

---

**Preconditions:**

- User is not logged in
- No account exists with email "newuser@example.com"
- Staging environment is accessible

---

**Test Steps:**

1. Navigate to "/signup"
   - **Verify:** Signup form is displayed

2. Enter email: "newuser@example.com"
   - **Verify:** Email field accepts the value

3. Enter password: "SecurePass123!"
   - **Verify:** Password is masked
   - **Verify:** Password strength indicator shows "Strong"

4. Click "Create Account" button
   - **Verify:** Loading indicator appears

---

**Expected Results:**

- **UI:** Success message "Account created! Check your email to verify."
- **UI:** Redirect to "/verify-email" page
- **Database:** New record in `profiles` table with:
  - email: "newuser@example.com"
  - created_at: [current timestamp]
  - email_verified: false
- **Email:** Verification email sent to "newuser@example.com"

---

**Test Data:**

```json
{
  "email": "newuser@example.com",
  "password": "SecurePass123!"
}
```
````

---

**Post-conditions:**

- Clean up: Delete test user from database after test

```

### 11.2 Nomenclatura de Test Cases

Usa formato claro:

```

Validar [COMPORTAMIENTO] [CONDICIÃ“N]

````

**Ejemplos:**
- `Validar signup exitoso con credenciales vÃ¡lidas`
- `Validar error de validaciÃ³n cuando email tiene formato invÃ¡lido`
- `Validar lÃ­mite de caracteres al ingresar exactamente 50 chars`
- `Validar rechazo de login cuando password es incorrecto`

### 11.3 Parametrized Tests

Cuando tienes el mismo test con diferentes datos, usa parametrizaciÃ³n:

```markdown
### TC-XX: Validar rechazo de email con formato invÃ¡lido (Parametrizado)

**Type:** Negative
**Priority:** High
**Test Level:** UI + API

---

**Test Data Sets:**

| # | Email Input | Expected Error Message |
|---|-------------|----------------------|
| 1 | "notanemail" | "Please enter a valid email address" |
| 2 | "@example.com" | "Please enter a valid email address" |
| 3 | "user@" | "Please enter a valid email address" |
| 4 | "user@.com" | "Please enter a valid email address" |
| 5 | "" (empty) | "Email is required" |

---

**Base Test Steps:**

1. Navigate to signup page
2. Enter email from data set
3. Try to submit form
4. **Verify:** Error message matches expected

---

**Benefit:** 5 test scenarios en 1 test case parametrizado
````

---

## Paso 12: Design Integration Tests

Si la story tiene integration points, diseÃ±a tests especÃ­ficos.

### 12.1 API Integration Test

```markdown
### IT-01: Validar integraciÃ³n Frontend â†’ Backend (Signup API)

**Integration Point:** Frontend â†’ POST /auth/signup
**Type:** Integration
**Priority:** High

---

**Test Flow:**

1. **Frontend sends request:**
```

POST /auth/signup
Content-Type: application/json

{
"email": "test@example.com",
"password": "SecurePass123!"
}

```

2. **Backend processes:**
- Validates input
- Creates user in Supabase Auth
- Creates profile in database
- Sends verification email

3. **Backend responds:**
```

HTTP 201 Created

{
"success": true,
"message": "Account created",
"user": {
"id": "uuid-xxx",
"email": "test@example.com"
}
}

```

4. **Frontend handles:**
- Shows success message
- Redirects to verify-email page

---

**Contract Validation (from api-contracts.yaml):**
- [ ] Request format matches spec
- [ ] Response format matches spec
- [ ] Status code is 201 for success
- [ ] Error responses match spec
```

---

## Paso 13: Document and Share Test Cases

### 13.1 Create test-cases.md

```
.context/PBI/epics/EPIC-MYM-2-.../stories/STORY-MYM-3-.../test-cases.md
```

Incluye:

- Critical Analysis (ambiguities, gaps, edge cases)
- Refined Acceptance Criteria
- All Test Cases
- Integration Tests
- Test Data Summary
- Questions for PO/Dev

### 13.2 Update Story in Jira

1. Edita la descripciÃ³n de la story
2. Agrega secciÃ³n:

```markdown
---

## ðŸ§ª QA Refinements (Shift-Left Analysis)

**Analysis Date:** [YYYY-MM-DD]
**Status:** Refined by QA

### Refined Acceptance Criteria
[Pegar scenarios refinados]

### Edge Cases Identified
1. [Edge case 1]
2. [Edge case 2]

### Test Coverage
- Test Cases: [X]
- Positive: [Y]
- Negative: [Z]
- Boundary: [W]

---
```

3. Agrega label: `shift-left-reviewed`

### 13.3 Add Comment with Test Cases

Agrega comentario con test cases completos y taggea al equipo.

---

## Checklist Final

### Feature Test Plan (Epic Level) âœ…

- [ ] Business context analyzed
- [ ] Technical architecture analyzed
- [ ] Risk analysis completed (technical, business, integration)
- [ ] Critical questions documented
- [ ] Test strategy defined (scope, levels, tools)
- [ ] Entry/Exit criteria defined
- [ ] Test cases estimated per story
- [ ] `feature-test-plan.md` created
- [ ] Epic updated in Jira
- [ ] Team notified

### Story Test Cases âœ…

- [ ] Story analyzed for ambiguities
- [ ] Missing information identified
- [ ] Edge cases identified
- [ ] Acceptance criteria refined with specific data
- [ ] Test cases designed (positive, negative, boundary)
- [ ] Integration tests designed (if applicable)
- [ ] Parametrization used where beneficial
- [ ] `test-cases.md` created
- [ ] Story updated in Jira
- [ ] Team notified

### Questions Resolved âœ…

- [ ] PO answered business questions
- [ ] Dev answered technical questions
- [ ] Test cases updated based on answers

---

## Troubleshooting

### "Story is too vague to test"

**SoluciÃ³n:** Convierte cada ambigÃ¼edad en una pregunta especÃ­fica para el PO. No asumas - pregunta.

### "Too many test cases"

**SoluciÃ³n:** Usa parametrizaciÃ³n. Si tienes 10 tests que solo varÃ­an en datos, hazlo 1 test parametrizado con 10 data sets.

### "Don't know what edge cases to consider"

**SoluciÃ³n:** Usa estas categorÃ­as:

- **Empty/Null:** Â¿QuÃ© pasa si el campo estÃ¡ vacÃ­o?
- **Boundary:** Â¿QuÃ© pasa en los lÃ­mites min/max?
- **Timing:** Â¿QuÃ© pasa si es muy lento/rÃ¡pido?
- **Concurrency:** Â¿QuÃ© pasa si dos usuarios hacen lo mismo?
- **State:** Â¿QuÃ© pasa si el sistema estÃ¡ en estado inesperado?

### "PO/Dev don't respond to questions"

**SoluciÃ³n:**

1. Tag directamente en Jira comment
2. Menciona que la implementaciÃ³n estÃ¡ bloqueada
3. PropÃ³n respuestas sugeridas para facilitar la discusiÃ³n

---

## Recursos Adicionales

- [Gherkin Reference](https://cucumber.io/docs/gherkin/reference/)
- [Test Case Design Techniques](https://www.guru99.com/test-case-design-techniques.html)
- [Boundary Value Analysis](https://www.softwaretestinghelp.com/boundary-value-analysis/)
- [Equivalence Partitioning](https://www.softwaretestinghelp.com/equivalence-partitioning-technique/)

---

## PrÃ³ximos Pasos

Con el shift-left testing completado, puedes proceder a:

1. **Fase 6: Planning** â†’ Crear implementation plans tÃ©cnicos
2. **Fase 7: Implementation** â†’ Dev implementa (con tests claros)
3. **Fase 10: Exploratory Testing** â†’ Ejecutar tests diseÃ±ados + exploratorio

Los test cases creados aquÃ­ se usarÃ¡n:

- Durante implementation (Dev tiene criterios claros)
- En exploratory testing (Fase 10)
- Para test documentation formal (Fase 11)
- Como base para automation (Fase 12)

---

**VersiÃ³n:** 1.0
**Ãšltima actualizaciÃ³n:** 2025-12-30
**Autor:** UPEX Galaxy - DOJO AI-Powered Quality Engineer
